# 2.3 Integer Arithmetic

Many beginning programmers are surprised to find that adding two positive numbers can yield a negative result, and that the comparison x\<y can yield a different result than the comparison x-y < 0. These properties are artifacts of the finite nature of computer arithmetic. Understanding the nuances of computer arithmetic can help programmers write more reliable code.

## 2.3.1 Unsigned Addition

Consider two nonnegative integers x and y, such that 0 ≤ x, y ≤ $$2^w$$-1. Each of these values can be represented by a w-bit unsigned number. If we compute their sum, however, we have a possible range 0 ≤ x + y ≤ $$2^{w+1}$$ − 2. Representing this sum could require w + 1 bits. For example, Figure 2.21 shows a plot of the function x + y when x and y have 4-bit representations. The arguments (shown on the horizontal axes) range from 0 to 15, but the sum ranges from 0 to 30. The shape of the function is a sloping plane (the function is linear in both dimensions). If we were to maintain the sum as a (w + 1)-bit number and add it to another value, we may require w + 2 bits, and so on. This continued “word size inflation” means we cannot place any bound on the word size required to fully represent the results of arithmetic operations. Some programming languages, such as **Lisp**, actually support arbitrary size arithmetic to allow integers of any size (within the memory limits of the computer, of course.) More commonly, programming languages support fixed-size arithmetic, and hence operations such as “addition” and “multiplication” differ from their counterpart operations over integers.

![Figure 2.21
Integer addition. With a 4-bit word size, the sum could require 5 bits](<../../.gitbook/assets/image (27) (1).png>)

Let us define the operation $$+^u_w$$ for arguments x and y, where 0 ≤ x, y ≤ $$2^w$$-1, as the result of truncating the integer sum x + y to be w bits long and then viewing the result as an unsigned number. This can be characterized as a form of modular arithmetic, computing the sum modulo $$2^w$$ by simply discarding any bits with weight greater than $$2^{w−1}$$ in the bit-level representation of x + y. For example, consider a 4-bit number representation with x = 9 and y = 12, having bit representations \[1001] and \[1100], respectively. Their sum is 21, having a 5-bit representation \[10101]. But if we discard the high-order bit, we get \[0101], that is, decimal value 5. This matches the value 21 mod 16 = 5.

We can characterize operation $$+^u_w$$ as follows:

![](<../../.gitbook/assets/image (31) (1) (1).png>)

The two cases of Equation 2.11 are illustrated in Figure 2.22, showing the sum x + y on the left mapping to the unsigned w-bit sum x $$+^u_w$$ y on the right. The normal case preserves the value of x + y, while the overflow case has the effect of decrementing this sum by $$2^w$$.

![Figure 2.22
Relation between integer addition and unsigned addition.
When x + y is greater than 2^w − 1, the sum overflows.](<../../.gitbook/assets/image (26).png>)

<mark style="color:blue;">**DERIVATION**</mark>**: Unsigned addition**

In general, we can see that if x + y < 2^w, the leading bit in the (w + 1)-bit representation of the sum will equal 0, and hence discarding it will not change the numeric value. On the other hand, if 2^w ≤ x + y < 2^{w+1}, the leading bit in the (w + 1)-bit representation of the sum will equal 1, and hence discarding it is equivalent to subtracting 2^w from the sum.

An arithmetic operation is said to **overflow** when the full integer result cannot fit within the word size limits of the data type. As Equation 2.11 indicates, overflow occurs when the two operands sum to 2^w or more. Figure 2.23 shows a plot of the unsigned addition function for word size w = 4. The sum is computed modulo 2^4 = 16. When x + y < 16, there is no overflow, and x $$+^u_4$$ y is simply x + y. This is shown as the region forming a sloping plane labeled “Normal.” When x + y ≥ 16, the addition overflows, having the effect of decrementing the sum by 16. This is shown as the region forming a sloping plane labeled “Overflow.”

![Figure 2.23
Unsigned addition. With a 4-bit word size, addition is performed modulo 16.](<../../.gitbook/assets/image (23) (1).png>)

When executing C programs, overflows are not signaled as errors. At times, however, we might wish to determine whether or not overflow has occurred.

![](<../../.gitbook/assets/image (10) (1) (1).png>)

As an illustration, in our earlier example, we saw that 9 $$+^u_4$$ 12 = 5. We can see that overflow occurred, since 5 < 9.

<mark style="color:blue;">**DERIVATION**</mark>**: Detecting overflow of unsigned addition**

Observe that x + y ≥ x, and hence if s did not overflow, we will surely have s ≥ x. On the other hand, if s did overflow, we have s = x + y − 2^w. Given that y < 2^w, we have y − 2^w < 0, and hence s = x + (y − 2^w) < x.

**Modular addition** forms a mathematical structure known as an **abelian group**, named after the Norwegian mathematician Niels Henrik Abel (1802–1829). That is, it is **commutative** (that’s where the “abelian” part comes in) and **associative**; it has an **identity element** 0, and every element has an **additive inverse**. Let us consider the set of w-bit unsigned numbers with addition operation $$+^u_ w$$. For every value x, there must be some value $$-^u_wx$$ such that $$-^u_wx$$ $$+^u_wx$$ = 0. This additive inverse operation can be characterized as follows:

![](<../../.gitbook/assets/image (22).png>)

This result can readily be derived by case analysis:

<mark style="color:blue;">**DERIVATION**</mark>**: Unsigned negation**

When x = 0, the additive inverse is clearly 0. For x > 0, consider the value 2^w − x. Observe that this number is in the range 0 < 2^w − x < 2^w. We can also see that (x + 2^w − x) mod 2w = 2w mod 2w = 0. Hence it is the inverse of x under $$+^u_w$$.

{% tabs %}
{% tab title="Practice Problem 2.27" %}
Write a function with the following prototype:

```c
/* Determine whether arguments can be added without overflow */
int uadd_ok(unsigned x, unsigned y);
```

This function should return 1 if arguments x and y can be added without causing overflow.
{% endtab %}

{% tab title="Practice Problem 2.28" %}
We can represent a bit pattern of length w = 4 with a single hex digit. For an unsigned interpretation of these digits, use Equation 2.12 to fill in the following table giving the values and the bit representations (in hex) of the unsigned additive inverses of the digits shown.

![](<../../.gitbook/assets/image (21) (1).png>)
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="Solution 2.27" %}
```c
int uadd_ok(unsigned x, unsigned y) {
    return (x+y>=x) && (x+y>=y);
}
```
{% endtab %}

{% tab title="Solution 2.28" %}
1        15        0xE

4       12        0xC

7        9         0x9

10      6         0x6

14      2         0x2
{% endtab %}
{% endtabs %}

## 2.3.2 Two’s-Complement Addition

With two’s-complement addition, we must decide what to do when the result is either too large (positive) or too small (negative) to represent. Given integer values x and y in the range −2^{w−1} ≤ x, y ≤ 2^{w−1} − 1, their sum is in the range −2^w ≤ x + y ≤ 2^w − 2, potentially requiring w + 1 bits to represent exactly. As before, we avoid ever-expanding data sizes by truncating the representa-tion to w bits. The result is not as familiar mathematically as modular addition, however. Let us define x $$+^t_w$$ y to be the result of truncating the integer sum x + y to be w bits long and then viewing the result as a two’s-complement number.

![](<../../.gitbook/assets/image (29) (1).png>)

This principle is illustrated in Figure 2.24, where the sum x + y is shown on the left, having a value in the range −2^w ≤ x + y ≤ 2^w − 2, and the result of truncating the sum to a w-bit two’s-complement number is shown on the right. (The labels “Case 1” to “Case 4” in this figure are for the case analysis of the formal derivation of the principle.) When the sum x + y exceeds $$TMax_w$$ (case 4), we say that **positive overflow** has occurred. In this case, the effect of truncation is to subtract 2^w from the sum. When the sum x + y is less than $$TMin_w$$ (case 1), we say that **negative overflow** has occurred. In this case, the effect of truncation is to add 2^w to the sum.

![Figure 2.24
Relation between integer and two’s-complement addition. When x + y is less than −2^{w−1}, there is a negative overflow. When it is greater than or equal to 2^{w−1}, there is a positive overflow.](<../../.gitbook/assets/image (28) (1).png>)

The w-bit two’s-complement sum of two numbers has the exact same bit-level representation as the unsigned sum. In fact, most computers use the same machine instruction to perform either unsigned or signed addition.

<mark style="color:blue;">**DERIVATION**</mark>**: Two’s-complement addition**

Since two’s-complement addition has the exact same bit-level representation as unsigned addition, we can characterize the operation $$+^t_w$$ as one of converting its arguments to unsigned, performing unsigned addition, and then converting back to two’s complement:

![](<../../.gitbook/assets/image (32) (1).png>)

![](<../../.gitbook/assets/image (13).png>)

As illustrations of two’s-complement addition, Figure 2.25 shows some examples when w = 4. Each example is labeled by the case to which it corresponds in the derivation of Equation 2.13. Note that 2^4 = 16, and hence negative overflow yields a result 16 more than the integer sum, and positive overflow yields a result 16 less. We include bit-level representations of the operands and the result. Observe that the result can be obtained by performing binary addition of the operands and truncating the result to 4 bits.

![Figure 2.25
Two’s-complement addition examples. The bit-level representation of the 4-bit two’s-complement sum can be obtained by performing binary addition of the operands and truncating the result to 4 bits.](<../../.gitbook/assets/image (30) (1).png>)

Figure 2.26 illustrates two’s-complement addition for word size w = 4. The operands range between −8 and 7. When x + y < −8, two’s-complement addition has a negative overflow, causing the sum to be incremented by 16. When −8 ≤ x + y < 8, the addition yields x + y. When x + y ≥ 8, the addition has a positive overflow, causing the sum to be decremented by 16. Each of these three ranges forms a sloping plane in the figure.

![Figure 2.26
Two’s-complement addition.
With a 4-bit word size, addition can have a negative overflow when x + y < −8 and a positive overflow when x + y ≥ 8.](<../../.gitbook/assets/image (19) (1).png>)

Equation 2.13 also lets us identify the cases where overflow has occurred:

![](<../../.gitbook/assets/image (20) (1).png>)

Figure 2.25 shows several illustrations of this principle for w = 4. The first entry shows a case of negative overflow, where two negative numbers sum to a positive one. The final entry shows a case of positive overflow, where two positive numbers sum to a negative one.

<mark style="color:blue;">**DERIVATION**</mark>**: Detecting overflow of two’s-complement addition**

Let us first do the analysis for positive overflow. If both x > 0 and y > 0 but s ≤ 0, then clearly positive overflow has occurred. Conversely, positive overflow requires (1) that x > 0 and y > 0 (otherwise, x + y < TMax\_w) and (2) that s ≤ 0 (from Equation 2.13). A similar set of arguments holds for negative overflow.

{% tabs %}
{% tab title="PP 2.29" %}
Fill in the following table in the style of Figure 2.25. Give the integer values of the 5-bit arguments, the values of both their integer and two’s-complement sums, the bit-level representation of the two’s-complement sum, and the case from the derivation of Equation 2.13.

| x     | y     | x+y | x+^t\_5y | Case |
| ----- | ----- | --- | -------- | ---- |
|       |       |     |          |      |
| 10100 | 10001 |     |          |      |
|       |       |     |          |      |
| 11000 | 11000 |     |          |      |
|       |       |     |          |      |
| 10111 | 01000 |     |          |      |
|       |       |     |          |      |
| 00010 | 00101 |     |          |      |
|       |       |     |          |      |
| 01100 | 00100 |     |          |      |
{% endtab %}

{% tab title="PP 2.30" %}
Write a function with the following prototype:

```c
/* Determine whether arguments can be added without overflow */
int tadd_ok(int x, int y);
```

This function should return 1 if arguments x and y can be added without causing overflow.
{% endtab %}

{% tab title="PP 2.31" %}
Your coworker gets impatient with your analysis of the overflow conditions for two’s-complement addition and presents you with the following implementation of `tadd_ok`:

```c
/* Determine whether arguments can be added without overflow */
/* WARNING: This code is buggy. */
int tadd_ok(int x, int y) {
    int sum = x+y;
    return (sum-x == y) && (sum-y == x);
}
```

You look at the code and laugh. Explain why.
{% endtab %}

{% tab title="PP 2.32" %}
You are assigned the task of writing code for a function `tsub_ok`, with arguments x and y, that will return 1 if computing x-y does not cause overflow. Having just written the code for Problem 2.30, you write the following:

```c
/* Determine whether arguments can be subtracted without overflow */
/* WARNING: This code is buggy. */
int tsub_ok(int x, int y) {
    return tadd_ok(x, -y);
}
```

For what values of x and y will this function give incorrect results? Writing a correct version of this function is left as an exercise (Problem 2.74).
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="S 2.29" %}
| x     | y     | x+y    | x+^t\_5y | Case |
| ----- | ----- | ------ | -------- | ---- |
| -12   | -15   | -27    | 5        | 1    |
| 10100 | 10001 | 100101 | 00101    |      |
| -8    | -8    | -16    | 8        | 1    |
| 11000 | 11000 | 110000 | 10000    |      |
| -9    | 8     | -1     | -1       | 2    |
| 10111 | 01000 | 111111 | 11111    |      |
| 2     | 5     | 7      | 7        | 3    |
| 00010 | 00101 | 000111 | 00111    |      |
| 12    | 4     | 16     | -16      | 4    |
| 01100 | 00100 | 10000  | 10000    |      |


{% endtab %}

{% tab title="S 2.30" %}
```c
/* Determine whether arguments can be added without overflow */
int tadd_ok(int x, int y) {
    return !((x>0 && y>0 && x+y<=0) ||
             (x<0 && y<0 && x+y>=0));
}
```
{% endtab %}

{% tab title="S 2.31" %}
if x = TMin or y = TMin, will cause -x or -y overflow.
{% endtab %}

{% tab title="S 2.32" %}
When y = TMin,  -y will overflow.

\-y also equal to TMin, cause this function give incorrect results.

```c
/* Determine whether arguments can be subtracted without overflow */
int tsub_ok(int x, int y) {
    if (y == INTMIN)
        return 0;
    else
        return tadd_ok(x, -y);
}
```
{% endtab %}
{% endtabs %}

## 2.3.3 Two’s-Complement Negation

We can see that every number x in the range $$TMin_w$$ ≤ x ≤ $$TMax_w$$ has an additive inverse under $$+^t_w$$, which we denote $$-^t_wx$$ as follows:

![](<../../.gitbook/assets/image (9) (1).png>)

That is, for w-bit two’s-complement addition, $$TMin_w$$ is its own additive inverse, while any other value x has −x as its additive inverse.

<mark style="color:blue;">**DERIVATION**</mark>**: Two’s-complement negation**

Observe that $$TMin_w$$ + $$TMin_w$$ = −2^{w−1} + −2^{w−1} = −2^w. This would cause negative overflow, and hence $$TMin_w$$ $$+^t_w$$ $$TMin_w$$ = −2^w + 2^w = 0. For values of x such that x > TMin\_w, the value −x can also be represented as a w-bit two’s-complement number, and their sum will be −x + x = 0.

{% tabs %}
{% tab title="Practice Problem 2.33 " %}
We can represent a bit pattern of length w = 4 with a single hex digit. For a two’s complement interpretation of these digits, fill in the following table to determine the additive inverses of the digits shown:

| x   |         | -^t\_4 x |     |
| --- | ------- | -------- | --- |
| Hex | Decimal | Decimal  | Hex |
| 2   |         |          |     |
| 3   |         |          |     |
| 9   |         |          |     |
| B   |         |          |     |
| C   |         |          |     |

What do you observe about the bit patterns generated by two’s-complement and unsigned (Problem 2.28) negation?
{% endtab %}

{% tab title="Solution 2.33" %}
| x   |         | -^t\_4 x |     |
| --- | ------- | -------- | --- |
| Hex | Decimal | Decimal  | Hex |
| 2   | 2       | -2       | E   |
| 3   | 3       | -3       | D   |
| 9   | -7      | 7        | 7   |
| B   | -5      | 5        | 5   |
| C   | -4      | 4        | 4   |
{% endtab %}
{% endtabs %}

#### <mark style="color:blue;">Web Aside DATA:TNEG</mark> --- Bit-level representation of two’s-complement negation

There are several clever ways to determine the two’s-complement negation of a value represented at the bit level. The following two techniques are both useful, such as when one encounters the value 0xfffffffa when debugging a program, and they lend insight into the nature of the two’s-complement representation.

One technique for performing two’s-complement negation at the bit level is to complement the bits and then increment the result. In C, we can state that for any integer value x, computing the expressions -x and \~x + 1 will give identical results.

Here are some examples with a 4-bit word size:

![](<../../.gitbook/assets/image (24) (1).png>)

For our earlier example, we know that the complement of 0xf is 0x0 and the complement of 0xa is 0x5, and so 0xfffffffa is the two’s-complement representation of −6.

A second way to perform two’s-complement negation of a number x is based on splitting the bit vector into two parts. Let k be the position of the rightmost 1, so the bit-level representation of x has the form \[$$x_{w−1}$$, $$x_{w−2}$$,...,$$x_{k+1}$$, 1, 0,... 0]. (This is possible as long as x != 0.) The negation is then written in binary form as \[\~$$x_{w−1}$$, \~$$x_{w−2}$$,... $$~x_{k+1}$$, 1, 0,..., 0]. That is, we complement each bit to the left of bit position k.

We illustrate this idea with some 4-bit numbers, where we highlight the rightmost pattern 1, 0,..., 0 in italics:

![](<../../.gitbook/assets/image (16).png>)

## 2.3.4 Unsigned Multiplication

Integers x and y in the range 0 ≤ x, y ≤ 2^w − 1 can be represented as w-bit unsigned numbers, but their product x\*y can range between 0 and (2^w − 1)^2 = 2^{2w} − 2^{w+1} + 1. This could require as many as 2w bits to represent. Instead, unsigned multiplication in C is defined to yield the w-bit value given by the low-order w bits of the 2w-bit integer product. Let us denote this value as x \*^u\_w y.

Truncating an unsigned number to w bits is equivalent to computing its value modulo 2^w, giving the following:

![](<../../.gitbook/assets/image (5).png>)

## 2.3.5 Two’s-Complement Multiplication

Integers x and y in the range $$−2^{w−1}$$ ≤ x,y ≤ $$2^{w−1} − 1$$ can be represented as w-bit two’s-complement numbers, but their product x\*y can range between $$−2^{w−1}$$ \* $$(2^{w−1} − 1)$$ = $$−2^{2w−2}$$ + $$2^{w−1}$$ and $$−2^{w−1}$$ \* $$−2^{w−1}$$ = $$2^{2w−2}$$. This could require as many as 2w bits to represent in two’s-complement form. Instead, signed multiplication in C generally is performed by truncating the 2w-bit product to w bits. We denote this value as x \*$$^t_w$$ y. Truncating a two’s-complement number to w bits is equivalent to first computing its value modulo $$2^w$$ and then converting from unsigned to two’s complement, giving the following:

![](<../../.gitbook/assets/image (28).png>)

We claim that the bit-level representation of the product operation is identical for both unsigned and two’s-complement multiplication, as stated by the following principle:

![](<../../.gitbook/assets/image (29).png>)

As illustrations, Figure 2.27 shows the results of multiplying different 3-bit numbers. For each pair of bit-level operands, we perform both unsigned and two’s-complement multiplication, yielding 6-bit products, and then truncate these to 3 bits. The unsigned truncated product always equals x\*y mod 8. The bitlevel representations of both truncated products are identical for both unsigned and two’s-complement multiplication, even though the full 6-bit representations differ.

![Figure 2.27
Three-bit unsigned and two’s-complement multiplication examples. Although the bit-level representations of the full products may differ, those of the truncated products are identical.](<../../.gitbook/assets/image (20).png>)

![](<../../.gitbook/assets/image (21).png>)

{% tabs %}
{% tab title="PP 2.34" %}
Fill in the following table showing the results of multiplying different 3-bit numbers, in the style of Figure 2.27:

![](<../../.gitbook/assets/image (10) (1).png>)

![](<../../.gitbook/assets/image (18) (1).png>)
{% endtab %}

{% tab title="PP 2.35" %}
You are given the assignment to develop code for a function `tmult_ok` that will determine whether two arguments can be multiplied without causing overflow. Here is your solution:

```c
/* Determine whether arguments can be multiplied without overflow */
int tmult_ok(int x, int y) {
    int p = x*y;
    /* Either x is zero, or dividing p by x gives y */
    return !x || p/x == y;
}
```

You test this code for a number of values of x and y, and it seems to work properly. Your coworker challenges you, saying, “If I can’t use subtraction to test whether addition has overflowed (see Problem 2.31), then how can you use division to test whether multiplication has overflowed?”

Devise a mathematical justification of your approach, along the following lines. First, argue that the case x = 0 is handled correctly. Otherwise, consider w-bit numbers x (x != 0), y, p, and q, where p is the result of performing two’s complement multiplication on x and y, and q is the result of dividing p by x.

1. Show that x \* y, the integer product of x and y, can be written in the form x \* y = p + t\*2^w, where t != 0 if and only if the computation of p overflows.
2. Show that p can be written in the form p = x \* q + r, where |r| < |x|.
3. Show that q = y if and only if r = t = 0.
{% endtab %}

{% tab title="PP 2.36" %}
For the case where data type `int` has 32 bits, devise a version of `tmult_ok` (Problem 2.35) that uses the 64-bit precision of data type `int64_t`, without using division.
{% endtab %}

{% tab title="PP 2.37" %}
You are given the task of patching the vulnerability in the `XDR` code shown below for the case where both data types `int` and `size_t` are 32 bits. You decide to eliminate the possibility of the multiplication overflowing by computing the number of bytes to allocate using data type `uint64_t`. You replace the original call to `malloc` (line 9) as follows:

```c
uint64_t asize = ele_cnt * (uint64_t) ele_size;
void *result = malloc(asize);
```

Recall that the argument to `malloc` has type `size_t`.

A. Does your code provide any improvement over the original?

B. How would you change the code to eliminate the vulnerability?
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="S 2.34" %}
4             5             20            010100          4           100

\-4           -3           12             001100          -4          100

2             7            14              001110           6           110

2           -1             -2              111110           -2          110

6           6             36              100100         4            100

\-2         -2            4                000100        -4           100
{% endtab %}

{% tab title="S 2.35" %}
If x=0, p = x\*y = 0, 肯定没有 overflow;

1\. x\*y  = $$\sum_{i=0}^{{2w-2}}$$$$x_i$$$$2^i$$  -  $$x_{2w-1}$$$$2^{2w-1}$$ = $$\sum_{{i=w}}^{{2w-2}}$$$$x_i$$$$2^i$$ - $$x_{2w-1}$$$$2^{2w-1}$$ + p + 2$$x_{w-1}$$$$2^{w-1}$$

&#x20;             \= p + t$$2^w$$ (t = $$\sum_{i=w}^{2w-2}x_i2^{i-w}$$ - $$x_{2w-1}2^{w-1}$$ + $$x_{w-1}$$)

&#x20;     So if t != 0, then x\*y !=p, means overflows.

2\.&#x20;
{% endtab %}

{% tab title="S 2.36" %}

{% endtab %}

{% tab title="S 2.37" %}
A. No, because malloc paramter is `size_t`, so just change `asize` to `uint64_t` eventually still to `size_t`.

B.

The best method is to detect overflow.

```c
int umult_ok(size_t x, size_t y) {
    size_t p = x*y;
    /* Either x is zero, or dividing p by x gives y */
    return !x || p/x == y;
}

if (!umult_ok(ele_cnt, ele_size) {
    return NULL;   
}
void *result = malloc(ele_cnt * ele_size);
...
...
...
```
{% endtab %}
{% endtabs %}

#### <mark style="color:blue;">Aside</mark> --- Security vulnerability in the XDR library

In 2002, it was discovered that code supplied by Sun Microsystems to implement the XDR library,\
a widely used facility for sharing data structures between programs, had a security vulnerability arising from the fact that multiplication can overflow without any notice being given to the program.

Code similar to that containing the vulnerability is shown below:

```c
/* Illustration of code vulnerability similar to that found in
 * Sun’s XDR library.
 */
void* copy_elements(void *ele_src[], int ele_cnt, size_t ele_size) {
    /*
     * Allocate buffer for ele_cnt objects, each of ele_size bytes
     * and copy from locations designated by ele_src
     */
    void *result = malloc(ele_cnt * ele_size);
    if (result == NULL)
        /* malloc failed */
        return NULL;
    void *next = result;
    int i;
    for (i = 0; i < ele_cnt; i++) {
        /* Copy object i to destination */
        memcpy(next, ele_src[i], ele_size);
        /* Move pointer to next memory region */
        next += ele_size;
    }
    return result;
}
```

The function `copy_elements` is designed to copy `ele_cnt` data structures, each consisting of `ele_ size` bytes into a buffer allocated by the function on line 9. The number of bytes required is computed as `ele_cnt * ele_size`.

Imagine, however, that a malicious programmer calls this function with ele\_cnt being 1,048,577 ($$2^{20}$$ + 1) and ele\_size being 4,096 ($$2^{12}$$) with the program compiled for 32 bits. Then the multiplication on line 9 will overflow, causing only 4,096 bytes to be allocated, rather than the 4,294,971,392 bytes required to hold that much data. The loop starting at line 15 will attempt to copy all of those bytes, overrunning the end of the allocated buffer, and therefore corrupting other data structures. This could cause the program to crash or otherwise misbehave.

The Sun code was used by almost every operating system and in such widely used programs as Internet Explorer and the Kerberos authentication system. The Computer Emergency Response Team (CERT), an organization run by the Carnegie Mellon Software Engineering Institute to track security vulnerabilities and breaches, issued advisory “CA-2002-25,” and many companies rushed to patch their code. Fortunately, there were no reported security breaches caused by this vulnerability.

A similar vulnerability existed in many implementations of the library function `calloc`. These have since been patched. Unfortunately, many programmers call allocation functions, such as `malloc`, using arithmetic expressions as arguments, without checking these expressions for overflow. Writing a reliable version of `calloc` is left as an exercise (Problem 2.76).

## 2.3.6 Multiplying by Constants

Historically, the integer multiply instruction on many machines was fairly slow, requiring 10 or more clock cycles, whereas other integer operations—such as addition, subtraction, bit-level operations, and shifting—required only 1 clock cycle. Even on the Intel Core i7 Haswell we use as our reference machine, integer multiply requires 3 clock cycles. As a consequence, one important optimization used by compilers is to attempt to replace multiplications by constant factors with combinations of shift and addition operations. We will first consider the case of multiplying by a power of 2, and then we will generalize this to arbitrary constants.

![](<../../.gitbook/assets/image (24).png>)

![](<../../.gitbook/assets/image (25).png>)

but this is also the case when performing multiplication on fixed-size words. We can therefore see that shifting a value left is equivalent to performing unsigned multiplication by a power of 2:

#### <mark style="color:blue;">PRINCIPLE</mark>: Unsigned multiplication by a power of 2

For C variables x and k with unsigned values x and k, such that 0 ≤ k\<w, the C expression x << k yields the value x \*$$^u_w$$ $$2^k$$.

Since the bit-level operation of fixed-size two’s-complement arithmetic is equivalent to that for unsigned arithmetic, we can make a similar statement about the relationship between left shifts and multiplication by a power of 2 for two’scomplement arithmetic:

#### <mark style="color:blue;">PRINCIPLE</mark>: Two’s-complement multiplication by a power of 2

For C variables x and k with two’s-complement value x and unsigned value k, such that 0 ≤ k\<w, the C expression x << k yields the value x \*$$^t_w$$ $$2^k$$.

Note that multiplying by a power of 2 can cause overflow with either unsigned or two’s-complement arithmetic. Our result shows that even then we will get the same effect by shifting. Returning to our earlier example, we shifted the 4-bit pattern \[1011] (numeric value 11) left by two positions to get \[101100] (numeric value 44). Truncating this to 4 bits gives \[1100] (numeric value 12 = 44 mod 16).

Given that integer multiplication is more costly than shifting and adding, many C compilers try to remove many cases where an integer is being multiplied by a constant with combinations of shifting, adding, and subtracting. For example, suppose a program contains the expression x\*14. Recognizing that 14 = 2^3 + 2^2 + 2^1, the compiler can rewrite the multiplication as (x<<3) + (x<<2) + (x<<1), replacing one multiplication with three shifts and two additions. The two computations will yield the same result, regardless of whether x is unsigned or two’s complement, and even if the multiplication would cause an overflow. Even better, the compiler can also use the property 14 = 2^4 − 2^1 to rewrite the multiplication as (x<<4) - (x<<1), requiring only two shifts and a subtraction.

Generalizing from our example, consider the task of generating code for the expression x \* K, for some constant K. The compiler can express the binary representation of K as an alternating sequence of zeros and ones:

\[(0 ... 0) (1 ... 1) (0 ... 0) ... (1 ... 1)]

For example, 14 can be written as \[(0 ... 0)(111)(0)]. Consider a run of ones from bit position n down to bit position m (n ≥ m). (For the case of 14, we have n = 3 and m = 1.) We can compute the effect of these bits on the product using either of two different forms:

Form A: (x<\<n) + (x<<(n − 1)) + ... + (x<\<m)\
Form B: (x<<(n + 1)) - (x<\<m)

By adding together the results for each run, we are able to compute x \* K without any multiplications. Of course, the trade-off between using combinations of shifting, adding, and subtracting versus a single multiplication instruction depends on the relative speeds of these instructions, and these can be highly machine dependent. Most compilers only perform this optimization when a small number of shifts, adds, and subtractions suffice.

{% tabs %}
{% tab title="PP 2.38" %}
As we will see in Chapter 3, the `LEA` instruction can perform computations of the form (a<\<k) + b, where k is either 0, 1, 2, or 3, and b is either 0 or some program value. The compiler often uses this instruction to perform multiplications by constant factors. For example, we can compute 3\*a as (a<<1) + a.

Considering cases where b is either 0 or equal to a, and all possible values of k, what multiples of a can be computed with a single `LEA` instruction?
{% endtab %}

{% tab title="PP 2.39" %}
How could we modify the expression for form B for the case where bit position n is the most significant bit?
{% endtab %}

{% tab title="PP 2.40" %}
For each of the following values of K, find ways to express x \* K using only the specified number of operations, where we consider both additions and subtractions to have comparable cost. You may need to use some tricks beyond the simple form A and B rules we have considered so far.

| K  | Shifts | Add/Subs | Experssion |
| -- | ------ | -------- | ---------- |
| 7  | 1      | 1        |            |
| 30 | 4      | 3        |            |
| 28 | 2      | 1        |            |
| 55 | 2      | 2        |            |
{% endtab %}

{% tab title="PP 2.41" %}
For a run of ones starting at bit position n down to bit position m (n ≥ m), we saw that we can generate two forms of code, A and B. How should the compiler decide which form to use?
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="S 2.38" %}
a\*n, n = 2^k or 2^k + 1 (k = 0, 1, 2, 3...)
{% endtab %}

{% tab title="S 2.39" %}
Modified Form B: (-x<<(n) + x<<(n) - (x<\<m)) = x<\<m
{% endtab %}

{% tab title="S 2.40" %}
| K  | Shifts | Add/Subs | Experssion                  |
| -- | ------ | -------- | --------------------------- |
| 7  | 1      | 1        | (x<<3)-x                    |
| 30 | 4      | 3        | (x<<4)+(x<<3)+(x<<2)+(x<<1) |
| 28 | 2      | 1        | (x<<5)-(x<<2)               |
| 55 | 2      | 2        | (x<<6)-x-(x<<3)             |
{% endtab %}

{% tab title="S 2.41" %}
when a run of ones' count more than 2, use B

less and equal than 2, use A
{% endtab %}
{% endtabs %}

## 2.3.7 Dividing by Powers of 2

Integer division on most machines is even slower than integer multiplication— requiring 30 or more clock cycles. Dividing by a power of 2 can also be performed using shift operations, but we use a right shift rather than a left shift. The two different right shifts—logical and arithmetic—serve this purpose for unsigned and two’s-complement numbers, respectively.

**Integer division always rounds toward zero**. To define this precisely, let us introduce some notation. For any real number a, define $$\lfloor a \rfloor$$ to be the unique integer a' such that a' ≤ a \<a' + 1. As examples, $$\lfloor {3.14} \rfloor$$ = 3, $$\lfloor−3.14\rfloor$$=−4, and $$\lfloor3\rfloor$$ = 3. Similarly, define $$\lceil a \rceil$$ to be the unique integer a' such that a' − 1 < a ≤ a' . As examples, $$\lceil 3.14 \rceil$$ = 4, $$\lceil −3.14 \rceil$$=−3, and $$\lceil 3 \rceil$$ = 3. For x ≥ 0 and y > 0, integer division should yield $$\lfloor x/y \rfloor$$, while for x < 0 and y > 0, it should yield $$\lceil x/y \rceil$$. That is, it should round down a positive result but round up a negative one.

The case for using shifts with unsigned arithmetic is straightforward, in part because right shifting is guaranteed to be performed logically for unsigned values.

#### <mark style="color:blue;">PRINCIPLE</mark>: Unsigned division by a power of 2

For C variables x and k with unsigned values x and k, such that 0 ≤ k\<w, the C expression x >> k yields the value $$\lfloor x/2k \rfloor$$.

As examples, Figure 2.28 shows the effects of performing logical right shifts on a 16-bit representation of 12,340 to perform division by 1, 2, 16, and 256. The zeros shifted in from the left are shown in italics. We also show the result we would obtain if we did these divisions with real arithmetic. These examples show that the result of shifting consistently rounds toward zero, as is the convention for integer division.

![Figure 2.28
Dividing unsigned numbers by powers of 2.
The examples illustrate how performing a logical right shift by k has the same effect as dividing by 2^k and then rounding toward zero.](<../../.gitbook/assets/image (19).png>)

#### <mark style="color:blue;">DERIVATION</mark>: Unsigned division by a power of 2

Let x be the unsigned integer represented by bit pattern $$[x_{w-1}, x_{w-2}, ..., x_0]$$, and let k be in the range 0 ≤ k\<w. Let x' be the unsigned number with w − k-bit representation \[$$x_{w−1}$$, $$x_{w−2}$$, ..., $$x_k$$], and let x'' be the unsigned number with k-bit representation \[$$x_{k−1}$$, ..., $$x_0$$]. We can therefore see that x = $$2^k$$x' + x'', and that 0 ≤ x'' < $$2^k$$. It therefore follows that $$\lfloor x/2k \rfloor$$ = x'.

Performing a logical right shift of bit vector $$[x_{w-1}, x_{w-2}, ..., x_0]$$ by k yields the bit vector

![](<../../.gitbook/assets/image (2).png>)

This bit vector has numeric value x' , which we have seen is the value that would result by computing the expression x >> k.

The case for dividing by a power of 2 with two’s-complement arithmetic is slightly more complex. First, the shifting should be performed using an arithmetic right shift, to ensure that negative values remain negative. Let us investigate what value such a right shift would produce.

#### <mark style="color:blue;">PRINCIPLE</mark>: Two’s-complement division by a power of 2, rounding down

Let C variables x and k have two’s-complement value x and unsigned value k, respectively, such that 0 ≤ k\<w. The C expression x >> k, when the shift is performed arithmetically, yields the value $$\lfloor x/2^k \rfloor$$.

For x ≥ 0, variable x has 0 as the most significant bit, and so the effect of an arithmetic shift is the same as for a logical right shift. Thus, an arithmetic right shift by k is the same as division by $$2^k$$ for a nonnegative number. As an example of a negative number, Figure 2.29 shows the effect of applying arithmetic right shift to a 16-bit representation of −12,340 for different shift amounts. For the case when no rounding is required (k = 1), the result will be $$x/2^k$$. When rounding is required, shifting causes the result to be rounded downward. For example, the shifting right by four has the effect of rounding −771.25 down to −772. We will need to adjust our strategy to handle division for negative values of x.

![Figure 2.29
Applying arithmetic right shift. The examples illustrate that arithmetic right shift is similar to division by a power of 2, except that it rounds down rather than toward zero.](<../../.gitbook/assets/image (31) (1).png>)

#### <mark style="color:blue;">DERIVATION</mark>: Two’s-complement division by a power of 2, rounding down

Let x be the two’s-complement integer represented by bit pattern $$[x_{w-1}, x_{w-2}, ..., x_0]$$, and let k be in the range 0 ≤ k\<w. Let x' be the two’s-complement number represented by the w − k bits $$[x_{w-1}, x_{w-2}, ..., x_k]$$, and let x'' be the unsigned number represented by the low-order k bits $$[x_{k-1}, ..., x_0]$$. By a similar analysis as the unsigned case, we have $$x = 2^kx' + x''$$ and $$0 ≤ x'' < 2^k$$, giving x' = $$\lfloor x/2k \rfloor$$. Furthermore, observe that shifting bit vector $$[x_{w-1}, x_{w-2}, ..., x_0]$$ right arithmetically by k yields the bit vector

![](<../../.gitbook/assets/image (27).png>)

which is the sign extension from w − k bits to w bits of $$[x_{w-1}, x_{w-2}, ..., x_k]$$. Thus, this shifted bit vector is the two’s-complement representation of $$\lfloor x/2k \rfloor$$.

We can correct for the improper rounding that occurs when a negative number is shifted right by “biasing” the value before shifting.

#### <mark style="color:blue;">PRINCIPLE</mark>: Two’s-complement division by a power of 2, rounding up

Let C variables x and k have two’s-complement value x and unsigned value k, respectively, such that 0 ≤ k\<w. The C expression (x + (1 << k) - 1) >> k, when the shift is performed arithmetically, yields the value $$\lceil x/2k \rceil$$.

Figure 2.30 demonstrates how adding the appropriate bias before performing the arithmetic right shift causes the result to be correctly rounded. In the third column, we show the result of adding the bias value to −12,340, with the lower k bits (those that will be shifted off to the right) shown in italics. We can see that the bits to the left of these may or may not be incremented. For the case where no rounding is required (k = 1), adding the bias only affects bits that are shifted off. For the cases where rounding is required, adding the bias causes the upper bits to be incremented, so that the result will be rounded toward zero.

![Figure 2.30
Dividing two’s-complement numbers by powers of 2.
By adding a bias before the right shift, the result is rounded toward zero.](<../../.gitbook/assets/image (30).png>)

The biasing technique exploits the property that $$\lceil x/y \rceil$$=$$\lfloor (x+y-1)/y \rfloor$$ for integers x and y such that y > 0. As examples, when x = −30 and y = 4, we have x + y − 1 = −27 and $$\lceil −30/4 \rceil$$= −7 = $$\lfloor −27/4 \rfloor$$. When x = −32 and y = 4, we have x + y − 1 = −29 and $$\lceil −32/4 \rceil$$= −8 = $$\lfloor −29/4 \rfloor$$.

#### <mark style="color:blue;">DERIVATION</mark>: Two’s-complement division by a power of 2, rounding up

To see that $$\lceil x/y \rceil$$=$$\lfloor (x + y − 1)/y \rfloor$$, suppose that x = qy + r, where 0 ≤ r\<y, giving (x + y − 1)/y = q + (r + y − 1)/y, and so $$\lfloor (x + y − 1)/y \rfloor$$ = q + $$\lfloor (r + y − 1)/y \rfloor$$. The latter term will equal 0 when r = 0 and 1 when r > 0. That is, by adding a bias of y − 1 to x and then rounding the division downward, we will get q when y divides x and q + 1 otherwise.

Returning to the case where $$y = 2^k$$, the C expression x + (1 << k) - 1 yields the value $$x + 2^k − 1$$. Shifting this right arithmetically by k therefore yields $$\lceil x/2^k \rceil$$.

These analyses show that for a two’s-complement machine using arithmetic right shifts, the C expression\
**(x<0 ? x+(1<\<k)-1 : x) >> k**\
will compute the value $$x/2^k$$.

We now see that division by a power of 2 can be implemented using logical or arithmetic right shifts. This is precisely the reason the two types of right shifts are available on most machines. Unfortunately, this approach does not generalize to division by arbitrary constants. Unlike multiplication, we cannot express division by arbitrary constants K in terms of division by powers of 2.

{% tabs %}
{% tab title="Practice Problem 2.42" %}
Write a function `div16` that returns the value x/16 for integer argument x. Your function should not use division, modulus, multiplication, any conditionals (`if` or `?:`), any comparison operators (e.g., <, >, or ==), or any loops. You may assume that data type `int` is 32 bits long and uses a two’s-complement representation, and that right shifts are performed arithmetically.
{% endtab %}

{% tab title="Practice Problem 2.43" %}
In the following code, we have omitted the definitions of constants M and N:

```c
#define M /* Mystery number 1 */
#define N /* Mystery number 2 */
int arith(int x, int y) {
    int result = 0;
    result = x*M + y/N; /* M and N are mystery numbers. */
    return result;
}
```

We compiled this code for particular values of M and N. The compiler optimized the multiplication and division using the methods we have discussed. The following is a translation of the generated machine code back into C:

```c
/* Translation of assembly code for arith */
int optarith(int x, int y) {
    int t = x;
    x <<= 5;
    x -= t;
    if (y < 0) y += 7;
    y >>= 3; /* Arithmetic shift */
    return x+y;
}
```

What are the values of M and N?
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="Solution 2.42" %}

{% endtab %}

{% tab title="Solution 2.43" %}
x = x << 5 - x, so n = 4 m = 0

M = 2^5-1 = 31

y = y<0? (y + 2^3 - 1) : y >> 3, so N = 2^3 = 8
{% endtab %}
{% endtabs %}

## 2.3.8 Final Thoughts on Integer Arithmetic

As we have seen, the “integer” arithmetic performed by computers is really a form of modular arithmetic. The finite word size used to represent numbers limits the range of possible values, and the resulting operations can overflow. We have also seen that the two’s-complement representation provides a clever way to represent both negative and positive values, while using the same bit-level implementations as are used to perform unsigned arithmetic—operations such as addition, subtraction, multiplication, and even division have either identical or very similar bit-level behaviors, whether the operands are in unsigned or two’scomplement form.

We have seen that some of the conventions in the C language can yield some surprising results, and these can be sources of bugs that are hard to recognize or understand. We have especially seen that the unsigned data type, while conceptually straightforward, can lead to behaviors that even experienced programmers do not expect. We have also seen that this data type can arise in unexpected ways—for example, when writing integer constants and when invoking library routines.

{% tabs %}
{% tab title="Practice Problem 2.44" %}
Assume data type `int` is 32 bits long and uses a two’s-complement representation for signed values. Right shifts are performed arithmetically for signed values and logically for unsigned values. The variables are declared and initialized as follows:

```c
int x = foo(); /* Arbitrary value */
int y = bar(); /* Arbitrary value */
unsigned ux = x;
unsigned uy = y;
```

For each of the following C expressions, either (1) argue that it is true (evaluates to 1) for all values of x and y, or (2) give values of x and y for which it is false (evaluates to 0):

A. (x > 0) || (x-1 < 0)

B. (x & 7) != 7 || (x<<29 < 0)

C. (x \* x) >= 0

D. x < 0 || -x <= 0

E. x > 0 || -x >= 0

F. x+y == uy+ux

G. x\*\~y+uy\*ux==-x
{% endtab %}

{% tab title="Solution 2.44" %}
A. false

B. false

C. false

D. true

E. false, when x = TMin < 0, -x = TMin < 0

F. true, x,y implicit cast to unsigned.

G.true, x,y implicit cast to unsigned.
{% endtab %}
{% endtabs %}
