# 2.2 Integer Representations

In this section, we describe two different ways bits can be used to encode integers — one that can only represent nonnegative numbers, and one that can represent negative, zero, and positive numbers. We will see later that they are strongly related both in their mathematical properties and their machine-level implementations. We also investigate the effect of expanding or shrinking an encoded integer to fit a representation with a different length.

Figure 2.8 lists the mathematical terminology we introduce to precisely define and characterize how computers encode and operate on integer data. This terminology will be introduced over the course of the presentation. The figure is included here as a reference.

![Figure 2.8
Terminology for integer data and arithmetic operations. The subscript w denotes the number of bits in the data representation.](<../../.gitbook/assets/image (13) (1) (1) (1).png>)

## 2.2.1 Integral Data Types

C supports a variety of integral data types — ones that represent finite ranges of integers. These are shown in Figures 2.9 and 2.10, along with the ranges of values they can have for “typical” 32- and 64-bit programs. Each type can specify a size with keyword `char`, `short`, `long`, as well as an indication of whether the represented numbers are all nonnegative (declared as unsigned), or possibly negative (the default.) As we saw in Figure 2.3, the number of bytes allocated for the different sizes varies according to whether the program is compiled for 32 or 64 bits. Based on the byte allocations, the different sizes allow different ranges of values to be represented. The only machine-dependent range indicated is for size designator long. Most 64-bit programs use an 8-byte representation, giving a much wider range of values than the 4-byte representation used with 32-bit programs.

![Figure 2.9
Typical ranges for C integral data types for 32-bit programs.](<../../.gitbook/assets/image (7) (1) (1).png>)

![Figure 2.10
Typical ranges for C integral data types for 64-bit programs.](<../../.gitbook/assets/image (17) (1) (1) (1) (1) (1).png>)

One important feature to note in Figures 2.9 and 2.10 is that the ranges are not symmetric—the range of negative numbers extends one further than the range of positive numbers. We will see why this happens when we consider how negative numbers are represented.

The C standards define minimum ranges of values that each data type must be able to represent. As shown in Figure 2.11, their ranges are the same or smaller than the typical implementations shown in Figures 2.9 and 2.10. In particular, with the exception of the fixed-size data types, we see that they require only a symmetric range of positive and negative numbers. We also see that data type `int` could be implemented with 2-byte numbers, although this is mostly a throwback to the days of 16-bit machines. We also see that size `long` can be implemented with 4-byte numbers, and it typically is for 32-bit programs. The fixed-size data types guarantee that the ranges of values will be exactly those given by the typical numbers of Figure 2.9, including the asymmetry between negative and positive.

![Figure 2.11
Guaranteed ranges for C integral data types. The C standards require that the data types have at least these ranges of values.](<../../.gitbook/assets/image (20) (1) (1) (1) (1).png>)

{% hint style="info" %}
#### New to C? --- Signed and unsigned numbers in C, C++, and Java

Both C and C++ support signed (the default) and unsigned numbers. Java supports only signed numbers.
{% endhint %}

## 2.2.2 Unsigned Encodings

Let us consider an integer data type of w bits. We write a bit vector as either <img src="../../.gitbook/assets/image (9) (1) (1) (1) (1) (1).png" alt="" data-size="line">, to denote the entire vector, or as \[$$x_{w-1}$$, $$x_{w-2}$$, ..., $$x_0$$] to denote the individual bits within the vector. Treating x as a number written in binary notation, we obtain the unsigned interpretation of x . In this encoding, each bit $$x_i$$ has value 0 or 1, with the latter case indicating that value $$2^i$$ should be included as part of the numeric value. We can express this interpretation as a function $$B2U_w$$ (for “binary to unsigned,” length w):

![](<../../.gitbook/assets/image (1) (1).png>)

In this equation, the notation <img src="../../.gitbook/assets/image (4).png" alt="" data-size="line"> means that the left-hand side is defined to be equal to the right-hand side. The function $$B2U_w$$ maps strings of zeros and ones of length w to nonnegative integers. As examples, Figure 2.12 shows the mapping, given by B2U, from bit vectors to integers for the following cases:

![](<../../.gitbook/assets/image (15) (1) (1) (1) (1) (1).png>)

In the figure, we represent each bit position i by a rightward-pointing blue bar of length $$2^i$$. The numeric value associated with a bit vector then equals the sum of the lengths of the bars for which the corresponding bit values are 1.

![Figure 2.12
Unsigned number examples for w = 4. When bit i in the binary representation has value 1, it contributes 2i to the value.](<../../.gitbook/assets/image (18) (1) (1) (1) (1) (1) (1).png>)

Let us consider the range of values that can be represented using w bits. The least value is given by bit vector \[00 ... 0] having integer value 0, and the greatest value is given by bit vector \[11 ... 1] having integer value <img src="../../.gitbook/assets/image (11) (1) (1) (1) (1).png" alt="" data-size="original"> = $$2^w$$ − 1. Using the 4-bit case as an example, we have $$UMax_4$$ = $$B2U_4$$(\[1111]) = $$2^4$$ − 1= 15. Thus, the function $$B2U_w$$ can be defined as a mapping $$B2U_w$$:$$\{0, 1\}^w$$ → {0, ..., $$UMax_w$$}.

The unsigned binary representation has the important property that every number between 0 and $$2^w$$ − 1 has a unique encoding as a w-bit value. For example, there is only one representation of decimal value 11 as an unsigned 4-bit number— namely, \[1011]. We highlight this as a mathematical principle, which we first state and then explain.

![](<../../.gitbook/assets/image (10) (1) (1) (1) (1).png>)

The mathematical term **bijection** refers to a function f that goes two ways: it maps a value x to a value y where y = f (x), but it can also operate in reverse, since for every y, there is a unique value x such that f (x) = y. This is given by the inverse function $$f^{−1}$$, where, for our example, x = $$f^{-1}$$(y). The function $$B2U_w$$ maps each bit vector of length w to a unique number between 0 and $$2^w$$ − 1, and it has an inverse, which we call $$U2B_w$$ (for “unsigned to binary”), that maps each number in the range 0 to $$2^w$$ − 1 to a unique pattern of w bits.

## 2.2.3 Two’s-Complement Encodings

For many applications, we wish to represent negative values as well. The most common computer representation of signed numbers is known as two’s-complement form. This is defined by interpreting the most significant bit of the word to have **negative weight**. We express this interpretation as a function $$B2T_w$$ (for “binary to two’s complement” length w):

![](<../../.gitbook/assets/image (12) (1) (1).png>)

The most significant bit $$x_{w−1}$$ is also called the sign bit. Its “weight” is $$−2^{w−1}$$, the negation of its weight in an unsigned representation. When the sign bit is set to 1, the represented value is negative, and when set to 0, the value is nonnegative. As examples, Figure 2.13 shows the mapping, given by B2T, from bit vectors to integers for the following cases:

![](<../../.gitbook/assets/image (20) (1) (1) (1).png>)

In the figure, we indicate that the sign bit has negative weight by showing it as a leftward-pointing gray bar. The numeric value associated with a bit vector is then given by the combination of the possible leftward-pointing gray bar and the rightward-pointing blue bars.

![Figure 2.13
Two’s-complement number examples for w = 4. Bit 3 serves as a sign bit; when set to 1, it contributes − = −8 to the value. This weighting is shown as a leftwardpointing gray bar.](<../../.gitbook/assets/image (14) (1) (1) (1).png>)

We see that the bit patterns are identical for Figures 2.12 and 2.13 (as well as for Equations 2.2 and 2.4), but the values differ when the most significant bit is 1, since in one case it has weight +8, and in the other case it has weight −8.

Let us consider the range of values that can be represented as a w-bit two’scomplement number. The least representable value is given by bit vector \[10 ... 0] (set the bit with negative weight but clear all others), having integer value <img src="../../.gitbook/assets/image (8) (1).png" alt="" data-size="line">. The greatest value is given by bit vector \[01 ... 1] (clear the bit with negative weight but set all others), having integer value ![](<../../.gitbook/assets/image (11) (1) (1) (1).png>) $$2^{w-1}$$-1. Using the 4-bit case as an example, we have $$TMin_4$$ = $$B2T_4$$(\[1000]) = −23 = −8 and $$TMax_4$$ = $$B2T_4$$(\[0111]) = 22 + 21 + 20 = 4 + 2 + 1 = 7.

We can see that $$B2T_w$$ is a mapping of bit patterns of length w to numbers between $$TMin_w$$ and $$TMax_w$$, written as $$B2T_w$$:$$\{0, 1\}^w$$ → {$$TMin_w$$,..., $$TMax_w$$}. As we saw with the unsigned representation, every number within the representable range has a unique encoding as a w-bit two’s-complement number. This leads to a principle for two’s-complement numbers similar to that for unsigned numbers:

![](<../../.gitbook/assets/image (10) (1) (1) (1).png>)

We define function $$T2B_w$$ (for “two’s complement to binary”) to be the inverse of $$B2T_w$$. That is, for a number x, such that $$TMin_w$$ ≤ x ≤ $$TMax_w$$, $$T2B_w$$(x) is the (unique) w-bit pattern that encodes x.

{% tabs %}
{% tab title="Practice Problem 2.17 " %}
Assuming w = 4, we can assign a numeric value to each possible hexadecimal digit, assuming either an unsigned or a two’s-complement interpretation. Fill in the following table according to these interpretations by writing out the nonzero powers of 2 in the summations shown in Equations 2.1 and 2.3:

![](<../../.gitbook/assets/image (18) (1) (1) (1) (1) (1).png>)
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="Solution 2.17" %}
0x1: 0001    2^1=1    2^1=1

0xB: 1011    2^3+2^1+2^0=11    -2^3+2^1+2=-5

0x2: 0010    2^1=2    2^1=2

0x7: 0111    2^2+2^1+2^0=7    2^2+2^1+2^0=7

0xC: 1100    2^3+2^2=12    -2^3+2^2=-4
{% endtab %}
{% endtabs %}

Figure 2.14 shows the bit patterns and numeric values for several important numbers for different word sizes. The first three give the ranges of representable integers in terms of the values of $$UMax_w$$, $$TMin_w$$, and $$TMax_w$$. We will refer to these three special values often in the ensuing discussion. We will drop the subscript w and refer to the values UMax, TMin, andTMax when w can be inferred from context or is not central to the discussion.

A few points are worth highlighting about these numbers. First, as observed in Figures 2.9 and 2.10, the two’s-complement range is asymmetric: |TMin| = |TMax| + 1; that is, there is no positive counterpart to TMin. As we shall see, this leads to some peculiar properties of two’s-complement arithmetic and can be the source of subtle program bugs. This asymmetry arises because half the bit patterns (those with the sign bit set to 1) represent negative numbers, while half (those with the sign bit set to 0) represent nonnegative numbers. Since 0 is nonnegative, this means that it can represent one less positive number than negative. Second, the maximum unsigned value is just over twice the maximum two’s-complement value: UMax = 2TMax + 1. All of the bit patterns that denote negative numbers in two’s-complement notation become positive values in an unsigned representation.

![Figure 2.14 Important numbers. Both numeric values and hexadecimal representations are shown.](<../../.gitbook/assets/image (15) (1) (1) (1) (1).png>)

{% hint style="info" %}
#### Aside --- More on fixed-size integer types

For some programs, it is essential that data types be encoded using representations with specific sizes. For example, when writing programs to enable a machine to communicate over the Internet according to a standard protocol, it is important to have data types compatible with those specified by the protocol. We have seen that some C data types, especially `long`, have different ranges on different machines, and in fact the C standards only specify the minimum ranges for any data type, not the exact ranges. Although we can choose data types that will be compatible with standard representations on most machines, there is no guarantee of portability.

We have already encountered the 32- and 64-bit versions of fixed-size integer types (Figure 2.3); they are part of a larger class of data types. The ISO C99 standard introduces this class of integer types in the file **stdint.h**. This file defines a set of data types with declarations of the form `intN_t` and `uintN_t`, specifying N-bit signed and unsigned integers, for different values of N. The exact values of N are implementation dependent, but most compilers allow values of 8, 16, 32, and 64. Thus, we can unambiguously declare an unsigned 16-bit variable by giving it type `uint16_t`, and a signed variable of 32 bits as `int32_t`.

Along with these data types are a set of macros defining the minimum and maximum values for each value of N. These have names of the form `INTN_MIN`, `INTN_MAX`, and `UINTN_MAX`.

Formatted printing with fixed-width types requires use of macros that expand into format strings in a system-dependent manner. So, for example, the values of variables x and y of type `int32_t` and `uint64_t` can be printed by the following call to printf:

`printf("x = %" PRId32 ", y = %" PRIu64 "\n", x, y);`

When compiled as a 64-bit program, macro PRId32 **** expands to the string "d", while PRIu64 expands to the pair of strings "l" "u". When the C preprocessor encounters a sequence of string constants separated only by spaces (or other whitespace characters), it concatenates them together. Thus, the above call to printf becomes

`printf("x = %d, y = %lu\n", x, y);`

Using the macros ensures that a correct format string will be generated regardless of how the code is compiled.
{% endhint %}

Figure 2.14 also shows the representations of constants −1 and 0. Note that −1 has the same bit representation as UMax — a string of all ones. Numeric value 0 is represented as a string of all zeros in both representations.

The C standards do not require signed integers to be represented in two’scomplement form, but nearly all machines do so. Programmers who are concerned with maximizing portability across all possible machines should not assume any particular range of representable values, beyond the ranges indicated in Figure 2.11, nor should they assume any particular representation of signed numbers. On the other hand, many programs are written assuming a two’s-complement representation of signed numbers, and the “typical” ranges shown in Figures 2.9 and 2.10, and these programs are portable across a broad range of machines and compilers. The file **\<limits.h>** in the C library defines a set of constants delimiting the ranges of the different integer data types for the particular machine on which the compiler is running. For example, it defines constants `INT_MAX`, `INT_MIN`, and `UINT_MAX` describing the ranges of signed and unsigned integers. For a two’s-complement machine in which data type int has w bits, these constants correspond to the values of $$TMax_w$$, $$TMin_w$$, and $$UMax_w$$.

The Java standard is quite specific about integer data type ranges and representations. It requires a two’s-complement representation with the exact ranges shown for the 64-bit case (Figure 2.10). In Java, the single-byte data type is called `byte` instead of `char`. These detailed requirements are intended to enable Java programs to behave identically regardless of the machines or operating systems running them.

To get a better understanding of the two’s-complement representation, consider the following code example:

```c
short x = 12345;
short mx = -x;

show_bytes((byte_pointer) &x, sizeof(short));
show_bytes((byte_pointer) &mx, sizeof(short));
```

When run on a big-endian machine, this code prints 30 39 and cf c7, indicating that `x` has hexadecimal representation 0x3039, while `mx` has hexadecimal representation 0xCFC7. Expanding these into binary, we get bit patterns \[0011000000111001] for `x` and \[1100111111000111] for `mx`. As Figure 2.15 shows, Equation 2.3 yields values 12,345 and −12,345 for these two bit patterns.

![Figure 2.15 Two’s-complement representations of 12,345 and −12,345, and unsigned representation of 53,191. Note that the latter two have identical bit representations.](<../../.gitbook/assets/image (16) (1) (1) (1).png>)

{% hint style="info" %}
#### Aside --- Alternative representations of signed numbers

There are two other standard representations for signed numbers:

**Ones’ complement**. This is the same as two’s complement, except that the most significant bit has weight −($$2^{w−1}$$ − 1) rather than −$$2^{w−1}$$:

<img src="../../.gitbook/assets/image (17) (1) (1) (1) (1).png" alt="" data-size="original">\
**Sign magnitude**. The most significant bit is a sign bit that determines whether the remaining bits should be given negative or positive weight:

![](<../../.gitbook/assets/image (9) (1) (1) (1) (1).png>)\
Both of these representations have the curious property that there are two different encodings of the number 0. For both representations, \[00 ... 0] is interpreted as +0. The value −0 can be represented in sign-magnitude form as \[10 ... 0] and in ones’ complement as \[11 ... 1]. Although machines based on ones’-complement representations were built in the past, almost all modern machines use two’s complement. We will see that sign-magnitude encoding is used with floating-point numbers.

Note the different position of apostrophes: two’s complement versus ones’ complement. The term “two’s complement” arises from the fact that for nonnegative x we compute a w-bit representation of −x as $$2^w$$ − x (a single two.) The term “ones’ complement” comes from the property that we can compute −x in this notation as \[111 ... 1] − x (multiple ones).
{% endhint %}

{% tabs %}
{% tab title="Practice Problem 2.18" %}
In Chapter 3, we will look at listings generated by a disassembler, a program that converts an executable program file back to a more readable ASCII form. These files contain many hexadecimal numbers, typically representing values in two’scomplement form. Being able to recognize these numbers and understand their significance (for example, whether they are negative or positive) is an important skill.

For the lines labeled A–I (on the right) in the following listing, convert the hexadecimal values (in 32-bit two’s-complement form) shown to the right of the instruction names (`sub`, `mov`, and `add`) into their decimal equivalents:

![](<../../.gitbook/assets/image (13) (1) (1).png>)
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="Solution 2.18" %}
A. 0x2e0 => 743

B. -0x58 => -88

C. 0x28 => 40

D. -0x30 => -48

E. 0x78 => 120

F. 0x88 => 136

G. 0x1f8 => 504

H. 0xc0 => 192

I. -0x48 => -72
{% endtab %}
{% endtabs %}

## 2.2.4 Conversions between Signed and Unsigned

C allows casting between different numeric data types. For example, suppose variable x is declared as `int` and u as `unsigned`. The expression (unsigned) x converts the value of x to an unsigned value, and (int) u converts the value of u to a signed integer. What should be the effect of casting signed value to unsigned, or vice versa? From a mathematical perspective, one can imagine several different conventions. Clearly, we want to preserve any value that can be represented in both forms. On the other hand, converting a negative value to unsigned might yield zero. Converting an unsigned value that is too large to be represented in two’scomplement form might yield TMax. For most implementations of C, however, the answer to this question is based on a bit-level perspective, rather than on a numeric one.

For example, consider the following code:

```c
short int v = -12345;
unsigned short uv = (unsigned short) v;
printf("v = %d, uv = %u\n", v, uv);
```

When run on a two’s-complement machine, it generates the following output:

`v = -12345, uv = 53191`

What we see here is that the effect of casting is to keep the bit values identical but change how these bits are interpreted. We saw in Figure 2.15 that the 16-bit two’s-complement representation of −12,345 is identical to the 16-bit unsigned representation of 53,191. Casting from `short` to `unsigned short` changed the numeric value, but not the bit representation.

Similarly, consider the following code:

```c
unsigned u = 4294967295u; /* UMax */
int tu = (int) u;
printf("u = %u, tu = %d\n", u, tu);
```

When run on a two’s-complement machine, it generates the following output:

`u = 4294967295, tu = -1`

We can see from Figure 2.14 that, for a 32-bit word size, the bit patterns representing 4,294,967,295 (`UMax32`) in unsigned form and −1 in two’s-complement form are identical. In casting from `unsigned` to `int`, the underlying bit representation stays the same.

This is a general rule for how most C implementations handle conversions between signed and unsigned numbers with the same word size—the numeric values might change, but the bit patterns do not. Let us capture this idea in a more mathematical form. We defined functions U2Bw and T2Bw that map numbers to their bit representations in either unsigned or two’s-complement form. That is, given an integer x in the range 0 ≤ x < UMaxw, the function U2Bw(x) gives the unique w-bit unsigned representation of x. Similarly, when x is in the range TMinw ≤ x ≤ TMaxw, the function T2Bw(x) gives the unique w-bit two’scomplement representation of x.

Now define the function $$T2U_w$$ as <img src="../../.gitbook/assets/image (21) (1) (1) (1) (1) (1).png" alt="" data-size="line">. This function takes a number between TMinw and TMaxw and yields a number between 0 and UMaxw, where the two numbers have identical bit representations, except that the argument has a two’s-complement representation while the result is unsigned. Similarly, for x between 0 and UMaxw, the function U2Tw, defined as <img src="../../.gitbook/assets/image (5) (1).png" alt="" data-size="line">B2Tw(U2Bw(x)), yields the number having the same two’s-complement representation as the unsigned representation of x.

Pursuing our earlier examples, we see from Figure 2.15 that $$T2U_{16}$$(−12,345) = 53,191, and that $$U2T_{16}$$(53,191) = −12,345. That is, the 16-bit pattern written in hexadecimal as 0xCFC7 is both the two’s-complement representation of −12,345 and the unsigned representation of 53,191. Note also that 12,345 + 53,191 = 65,536 = $$2^{16}$$. This property generalizes to a relationship between the two numeric values (two’s complement and unsigned) represented by a given bit pattern. Similarly, from Figure 2.14, we see that $$T2U_{32}$$(−1) = 4,294,967,295, and $$U2T_{32}$$(4,294,967,295) = −1. That is, UMax has the same bit representation in unsigned form as does −1 in two’s-complement form. We can also see the relationship between these two numbers: 1 + UMaxw = $$2^w$$.

We see, then, that function T2U describes the conversion of a two’scomplement number to its unsigned counterpart, while U2T converts in the opposite direction. These describe the effect of casting between these data types in most C implementations.

{% tabs %}
{% tab title="Practice Problem 2.19" %}
Using the table you filled in when solving Problem 2.17, fill in the following table describing the function $$T2U_4$$:

![](<../../.gitbook/assets/image (15) (1) (1) (1).png>)
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="Solution 2.19" %}
\-1: 15

\-5: 11

\-6: 10

\-4: 12

1: 1

8: 8
{% endtab %}
{% endtabs %}

The relationship we have seen, via several examples, between the two’scomplement and unsigned values for a given bit pattern can be expressed as a property of the function T2U:

![](<../../.gitbook/assets/image (14) (1) (1).png>)

For example, we saw that$$T2U_{16}$$(−12,345) = −12,345 + $$2^{16}$$ = 53,191, and also that $$T2U_w$$(−1) = −1 + $$2^w$$ = $$UMax_w$$.

This property can be derived by comparing Equations 2.1 and 2.3.

<mark style="color:blue;">DERIVATION</mark>: Conversion from two’s complement to unsigned

Comparing Equations 2.1 and 2.3, we can see that for bit pattern $$\vec{x}$$ , if we compute the difference $$B2U_w$$(x) − $$B2T_w$$(x) , the weighted sums for bits from 0 to w − 2 will cancel each other, leaving a value $$B2U_w(\vec{x})$$ − $$B2T_w(\vec{x})$$ = $$x_{w−1}$$($$2^{w−1}$$ −$$-2^{w−1}$$) = $$x_{w−1}2^w$$. This gives a relationship $$B2U_w(\vec{x})$$ = $$B2T_w(\vec{x})$$ + $$x_{w−1}2^w$$. We therefore have

![](<../../.gitbook/assets/image (21) (1) (1) (1) (1).png>)

In a two’s-complement representation of x, bit $$x_{w−1}$$ determines whether or not x is negative, giving the two cases of Equation 2.5.

As examples, Figure 2.16 compares how functions B2U and B2T assign values to bit patterns for w = 4. For the two’s-complement case, the most significant bit serves as the sign bit, which we diagram as a leftward-pointing gray bar. For the unsigned case, this bit has positive weight, which we show as a rightward-pointing black bar. In going from two’s complement to unsigned, the most significant bit changes its weight from −8 to +8. As a consequence, the values that are negative in a two’s-complement representation increase by $$2^4$$ = 16 with an unsigned representation. Thus, −5 becomes +11, and −1 becomes +15.

![Figure 2.16 Comparing unsigned and two’s-complement representations for w = 4. The weight of the most significant bit is −8 for two’s complement and +8 for unsigned, yielding a net difference of 16.](<../../.gitbook/assets/image (16) (1) (1).png>)

Figure 2.17 illustrates the general behavior of function T2U. As it shows, when mapping a signed number to its unsigned counterpart, negative numbers are converted to large positive numbers, while nonnegative numbers remain unchanged.

![Figure 2.17 Conversion from two’s complement to unsigned. Function T2U converts negative numbers to large positive numbers.](<../../.gitbook/assets/image (19) (1) (1) (1).png>)

{% tabs %}
{% tab title="Practice Problem 2.20" %}
Explain how Equation 2.5 applies to the entries in the table you generated when solving Problem 2.19.
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="Solution 2.20" %}
\-1+2^4=15

\-5+2^4=11

\-6+2^4=10

\-4+2^4=12

1=1

8=8
{% endtab %}
{% endtabs %}

Going in the other direction, we can state the relationship between an unsigned number u and its signed counterpart $$U2T_w$$(u):

![](<../../.gitbook/assets/image (13) (1).png>)

<mark style="color:blue;">DERIVATION</mark>: Unsigned to two’s-complement conversion

Let $$\vec{u}$$ = $$U2B_w(u)$$. This bit vector will also be the two’s-complement representation of $$U2T_w(u)$$. Equations 2.1 and 2.3 can be combined to give

![](<../../.gitbook/assets/image (11) (1) (1).png>)

In the unsigned representation of u, bit $$u_{w−1}$$ determines whether or not u is greater than $$TMax_w$$ = $$2^{w−1}$$ − 1, giving the two cases of Equation 2.7.

The behavior of function U2T is illustrated in Figure 2.18. For small (≤ $$TMax_w$$) numbers, the conversion from unsigned to signed preserves the numeric value. Large (> $$TMax_w$$) numbers are converted to negative values.

![Figure 2.18 Conversion from unsigned to two’s complement. Function U2T converts numbers greater than  − 1 to negative values.](<../../.gitbook/assets/image (6).png>)

To summarize, we considered the effects of converting in both directions between unsigned and two’s-complement representations. For values x in the range 0 ≤ x ≤ $$TMax_w$$, we have $$T2U_w(x)$$ = x and $$U2T_w(x)$$ = x. That is, numbers in this range have identical unsigned and two’s-complement representations. For values outside of this range, the conversions either add or subtract $$2^w$$. For example, we have $$T2U_w(−1)$$ = −1 + $$2^w$$ = $$UMax_w$$ — the negative number closest to zero maps to the largest unsigned number. At the other extreme, one can see that $$T2Uw(TMinw)$$ = $$−2^{w−1}$$ + $$2^w$$ = $$2^{w−1}$$ = $$TMax_w$$ + 1 — the most negative number maps to an unsigned number just outside the range of positive two’s-complement numbers. Using the example of Figure 2.15, we can see that $$T2U_{16}(−12,345)$$ = 65,536 + −12,345 = 53,191.

## 2.2.5 Signed versus Unsigned in C

As indicated in Figures 2.9 and 2.10, C supports both signed and unsigned arithmetic for all of its integer data types. Although the C standard does not specify a particular representation of signed numbers, almost all machines use two’s complement. Generally, most numbers are signed by default. For example, when declaring a constant such as 12345 or 0x1A2B, the value is considered signed. Adding character ‘U’ or ‘u’ as a suffix creates an unsigned constant; for example, 12345U or 0x1A2Bu.

C allows conversion between unsigned and signed. Although the C standard does not specify precisely how this conversion should be made, most systems follow the rule that the underlying bit representation does not change. This rule has the effect of applying the function $$U2T_w$$ when converting from unsigned to signed, and $$T2U_w$$ when converting from signed to unsigned, where w is the number of bits for the data type.

Conversions can happen due to **explicit** casting, such as in the following code:

```c
int tx, ty;
unsigned ux, uy;

tx = (int) ux;
uy = (unsigned) ty;
```

Alternatively, they can happen **implicitly** when an expression of one type is assigned to a variable of another, as in the following code:

```c
int tx, ty;
unsigned ux, uy;

tx = ux; /* Cast to signed */
uy = ty; /* Cast to unsigned */
```

When printing numeric values with `printf`, the directives `%d`, `%u`, and `%x` are used to print a number as a signed decimal, an unsigned decimal, and in hexadecimal format, respectively. Note that printf does not make use of any type information, and so it is possible to print a value of type `int` with directive `%u` and a value of type `unsigned` with directive `%d`. For example, consider the following code:

```c
int x = -1;
unsigned u = 2147483648; /* 2 to the 31st */

printf("x = %u = %d\n", x, x);
printf("u = %u = %d\n", u, u);
```

When compiled as a 32-bit program, it prints the following:

x = 4294967295 = -1\
u = 2147483648 = -2147483648

In both cases, `printf` prints the word first as if it represented an unsigned number and second as if it represented a signed number. We can see the conversion routines in action: $$T2U_{32}(−1)$$ = $$UMax_{32}$$ = $$2^{32}$$ − 1 and $$U2T_{32}(2^{31})$$ = $$2^{31}$$ − $$2^{32}$$ = −$$2^{31}$$ = $$TMin_{32}$$.

Some possibly nonintuitive behavior arises due to C’s handling of expressions containing combinations of signed and unsigned quantities. When an operation is performed where one operand is signed and the other is unsigned, C implicitly casts the signed argument to unsigned and performs the operations assuming the numbers are nonnegative. As we will see, this convention makes little difference for standard arithmetic operations, but it leads to nonintuitive results for relational operators such as < and >. Figure 2.19 shows some sample relational expressions and their resulting evaluations, when data type int has a 32-bit two’s-complement representation. Consider the comparison -1 < 0U. Since the second operand is unsigned, the first one is implicitly cast to unsigned, and hence the expression is equivalent to the comparison 4294967295U < 0U (recall that $$T2U_w(−1)$$ = $$UMax_w$$), which of course is false. The other cases can be understood by similar analyses.

![Figure 2.19 Effects of C promotion rules. Nonintuitive cases are marked by ‘\*’. When either operand of a comparison is unsigned, the other operand is implicitly cast to unsigned. See Web Aside DATA:TMIN for why we write  as -2,147,483,647-1.](<../../.gitbook/assets/image (2) (1).png>)

{% hint style="info" %}
#### Web Aside DATA:TMIN --- Writing TMin in C

In Figure 2.19 and in Problem 2.21, we carefully wrote the value of $$TMin_{32}$$ as -2,147,483,647-1. Why not simply write it as either -2,147,483,648 or 0x80000000? Looking at the C header file limits.h, we see that they use a similar method as we have to write $$TMin_{32}$$ and $$TMax_{32}$$:

/\* Minimum and maximum values a ‘signed int’ can hold. \*/\
\#define INT\_MAX 2147483647\
\#define INT\_MIN (-INT\_MAX - 1)

Unfortunately, a curious interaction between the asymmetry of the two’s-complement representation and the conversion rules of C forces us to write $$TMin_{32}$$ in this unusual way. Although understanding this issue requires us to delve into one of the murkier corners of the C language standards, it will help us appreciate some of the subtleties of integer data types and representations.
{% endhint %}



{% tabs %}
{% tab title="Practice Problem 2.21" %}
Assuming the expressions are evaluated when executing a 32-bit program on a machine that uses two’s-complement arithmetic, fill in the following table describing the effect of casting and relational operations, in the style of Figure 2.19:

![](<../../.gitbook/assets/image (9) (1) (1) (1).png>)
{% endtab %}

{% tab title="Solution 2.21" %}
\-2147483647-1 == 2147483648U    Unsigned    1\*

\-2147483647-1 < 2147483647         Signed         1

\-2147483647-1U < 2147483647       Unsigned    0\*

\-2147483647-1 < -2147483647        Signed         1

\-2147483647-1U < -2147483647      Unsigned    1
{% endtab %}
{% endtabs %}

## 2.2.6 Expanding the Bit Representation of a Number

One common operation is to convert between integers having different word sizes while retaining the same numeric value. Of course, this may not be possible when the destination data type is too small to represent the desired value. Converting from a smaller to a larger data type, however, should always be possible.

To convert an unsigned number to a larger data type, we can simply add leading zeros to the representation; this operation is known as **zero extension**, expressed by the following principle:

![](<../../.gitbook/assets/image (17) (1) (1) (1).png>)

This principle can be seen to follow directly from the definition of the unsigned encoding, given by Equation 2.1.

For converting a two’s-complement number to a larger data type, the rule is to perform a **sign extension**, adding copies of the most significant bit to the representation, expressed by the following principle. We show the sign bit $$x_{w−1}$$ in blue to highlight its role in sign extension.

![](<../../.gitbook/assets/image (14) (1).png>)

As an example, consider the following code:

```c
short sx = -12345; /* -12345 */
unsigned short usx = sx; /* 53191 */
int x = sx; /* -12345 */
unsigned ux = usx; /* 53191 */

printf("sx = %d:\t", sx);
show_bytes((byte_pointer) &sx, sizeof(short));
printf("usx = %u:\t", usx);
show_bytes((byte_pointer) &usx, sizeof(unsigned short));
printf("x = %d:\t", x);
show_bytes((byte_pointer) &x, sizeof(int));
printf("ux = %u:\t", ux);
show_bytes((byte_pointer) &ux, sizeof(unsigned));
```

When run as a 32-bit program on a big-endian machine that uses a two’s complement representation, this code prints the output

```
sx = -12345: cf c7
usx = 53191: cf c7
x = -12345: ff ff cf c7
ux = 53191: 00 00 cf c7
```

We see that, although the two’s-complement representation of −12,345 and the unsigned representation of 53,191 are identical for a 16-bit word size, they differ for a 32-bit word size. In particular, −12,345 has hexadecimal representation 0xFFFFCFC7, while 53,191 has hexadecimal representation 0x0000CFC7. The former has been sign extended — 16 copies of the most significant bit 1, having hexadecimal representation 0xFFFF, have been added as leading bits. The latter has been extended with 16 leading zeros, having hexadecimal representation 0x0000.

As an illustration, Figure 2.20 shows the result of expanding from word size w = 3 to w = 4 by sign extension. Bit vector \[101] represents the value −4 + 1= −3. Applying sign extension gives bit vector \[1101] representing the value −8 + 4 + 1 = −3. We can see that, for w = 4, the combined value of the two most significant bits, −8 + 4 = −4, matches the value of the sign bit for w = 3. Similarly, bit vectors \[111] and \[1111] both represent the value −1.

![Figure 2.20 Examples of sign extension from w = 3 to w = 4. For w = 4, the combined weight of the upper 2 bits is −8 + 4 = −4, matching that of the sign bit for w = 3.](<../../.gitbook/assets/image (18) (1) (1) (1) (1).png>)

With this as intuition, we can now show that sign extension preserves the value of a two’s-complement number.

<mark style="color:blue;">DERIVATION</mark>: Expansion of a two’s-complement number by sign extension

Let w' = w + k. What we want to prove is that

![](<../../.gitbook/assets/image (21) (1) (1) (1).png>)

The proof follows by induction on k. That is, if we can prove that sign extending by 1 bit preserves the numeric value, then this property will hold when sign extending by an arbitrary number of bits. Thus, the task reduces to proving that

![](<../../.gitbook/assets/image (12) (1).png>)

Expanding the left-hand expression with Equation 2.3 gives the following:

![](<../../.gitbook/assets/image (7) (1).png>)

The key property we exploit is that $$2^w$$ − $$2^{w−1}$$ = $$2^{w−1}$$. Thus, the combined effect of adding a bit of weight $$−2^w$$ and of converting the bit having weight $$−2^{w−1}$$ to be one with weight $$2^{w−1}$$ is to preserve the original numeric value.

{% tabs %}
{% tab title="Practice Problem 2.22" %}
Show that each of the following bit vectors is a two’s-complement representation of −4 by applying Equation 2.3:

A. \[1100]

B. \[11100]

C. \[111100]

Observe that the second and third bit vectors can be derived from the first by sign extension.
{% endtab %}

{% tab title="Practice Problem 2.23" %}
Consider the following C functions:

```c
int fun1(unsigned word) {
    return (int) ((word << 24) >> 24);
}

int fun2(unsigned word) {
    return ((int) word << 24) >> 24;
}
```

Assume these are executed as a 32-bit program on a machine that uses two’s complement arithmetic. Assume also that right shifts of signed values are performed arithmetically, while right shifts of unsigned values are performed logically.

A. Fill in the following table showing the effect of these functions for several example arguments. You will find it more convenient to work with a hexadecimal representation. Just remember that hex digits 8 through F have their most significant bits equal to 1.

![](<../../.gitbook/assets/image (15) (1) (1).png>)

B. Describe in words the useful computation each of these functions performs.
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="Solution 2.22" %}
A. -2^3 + 2^2 = -4

B. -2^4 + 2^3 + 2^2 = -4

C. -2^5 + 2^4 + 2^3 + 2^2 = -4
{% endtab %}

{% tab title="Solution 2.23" %}
A.

0x0000'0076    0x0000'0076    0x0000'0076

0x8765'4321    0x0000'0021    0x0000'0021

0x0000'00C9    0x0000'00C9    0xFFFF'FFC9

0xEDCB'A987    0x0000'0087    0xFFFF'FF87



B.

`fun1` 是计算最后一个字节的无符号值；

`fun2` 是计算最后一个字节的有符号值。
{% endtab %}
{% endtabs %}

## 2.2.7 Truncating Numbers

Suppose that, rather than extending a value with extra bits, we reduce the number of bits representing a number. This occurs, for example, in the following code:

```c
int x = 53191;
short sx = (short) x; /* -12345 */
int y = sx; /* -12345 */
```

Casting x to be `short` will truncate a 32-bit `int` to a 16-bit `short`. As we saw before, this 16-bit pattern is the two’s-complement representation of −12,345. When casting this back to `int`, sign extension will set the high-order 16 bits to ones, yielding the 32-bit two’s-complement representation of −12,345.

When truncating a w-bit number <img src="../../.gitbook/assets/image (7).png" alt="" data-size="original">to a k-bit number, we drop the high-order w−k bits, giving a bit vector ![](<../../.gitbook/assets/image (15) (1).png>). Truncating a number can alter its value—a form of overflow. For an unsigned number, we can readily characterize the numeric value that will result.

![](<../../.gitbook/assets/image (9) (1) (1).png>)

The intuition behind this principle is simply that all of the bits that were truncated have weights of the form $$2^i$$ , where i ≥ k, and therefore each of these weights reduces to zero under the modulus operation. This is formalized by the following derivation:

<mark style="color:blue;">DERIVATION</mark>: Truncation of an unsigned number

Applying the modulus operation to Equation 2.1 yields

![](<../../.gitbook/assets/image (17) (1) (1).png>)

In this derivation, we make use of the property that $$2^i$$ mod $$2^k$$ = 0 for any i ≥ k.

A similar property holds for truncating a two’s-complement number, except that it then converts the most significant bit into a sign bit:

![](<../../.gitbook/assets/image (17).png>)

In this formulation, x mod $$2^k$$ will be a number between 0 and $$2^k$$ − 1. Applying function $$U2T_k$$ to it will have the effect of converting the most significant bit $$x_{k−1}$$ from having weight $$2^{k−1}$$ to having weight $$−2^{k−1}$$. We can see this with the example of converting value x = 53,191 from `int` to `short`. Since $$2^{16}$$ = 65,536 ≥ x, we have x mod $$2^{16}$$ = x. But when we convert this number to a 16-bit two’s-complement number, we get x' = 53,191 − 65,536 = −12,345.

{% tabs %}
{% tab title="Practice Problem 2.24" %}
Suppose we truncate a 4-bit value (represented by hex digits 0 through F) to a 3- bit value (represented as hex digits 0 through 7.) Fill in the table below showing the effect of this truncation for some cases, in terms of the unsigned and two’scomplement interpretations of those bit patterns.

![](<../../.gitbook/assets/image (8).png>)

Explain how Equations 2.9 and 2.10 apply to these cases.
{% endtab %}

{% tab title="Solution 2.24" %}
1              1

3             3

5             5

4           -4

6           -2
{% endtab %}
{% endtabs %}

## 2.2.8 Advice on Signed versus Unsigned

As we have seen, the implicit casting of signed to unsigned leads to some nonintuitive behavior. Nonintuitive features often lead to program bugs, and ones involving the nuances of implicit casting can be especially difficult to see. Since the casting takes place without any clear indication in the code, programmers often overlook its effects.

The following two practice problems illustrate some of the subtle errors that can arise due to implicit casting and the unsigned data type.

{% tabs %}
{% tab title="Practice Problem 2.25" %}
Consider the following code that attempts to sum the elements of an array a, where the number of elements is given by parameter length:

```c
/* WARNING: This is buggy code */
float sum_elements(float a[], unsigned length) {
    int i;
    float result = 0;

    for (i = 0; i <= length-1; i++)
        result += a[i];
    return result;
}
```

When run with argument length equal to 0, this code should return 0.0. Instead, it encounters a memory error. Explain why this happens. Show how this code can be corrected.
{% endtab %}

{% tab title="Practice Problem 2.26" %}
You are given the assignment of writing a function that determines whether one string is longer than another. You decide to make use of the string library function `strlen` having the following declaration:

```c
/* Prototype for library function strlen */
size_t strlen(const char *s);
```

Here is your first attempt at the function:

```c
/* Determine whether string s is longer than string t */
/* WARNING: This function is buggy */
int strlonger(char *s, char *t) {
    return strlen(s) - strlen(t) > 0;
}
```

When you test this on some sample data, things do not seem to work quite right. You investigate further and determine that, when compiled as a 32-bit program, data type `size_t` is defined (via `typedef`) in header file stdio.h to be unsigned.

A. For what cases will this function produce an incorrect result?

B. Explain how this incorrect result comes about.

C. Show how to fix the code so that it will work reliably.
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="Solution 2.25" %}
Because length is unsigned number, \
length-1 will over flow and calculated value is Umax, so access a\[i] will cause memory error.

Correct:

i < length
{% endtab %}

{% tab title="Solution 2.26" %}
A. When strlen(s) < strlen(t) will produce incorrect result.

B. Unsigned overflow.

C. "strlen(s) - strlen(t) > 0" change to "strlen(s) < strlen(t)"
{% endtab %}
{% endtabs %}

We have seen multiple ways in which the subtle features of unsigned arithmetic, and especially the implicit conversion of signed to unsigned, can lead to errors or vulnerabilities. One way to avoid such bugs is to never use unsigned numbers. In fact, few languages other than C support unsigned integers. Apparently, these other language designers viewed them as more trouble than they are worth. For example, Java supports only signed integers, and it requires that they be implemented with two’s-complement arithmetic. The normal right shift operator >> is guaranteed to perform an arithmetic shift. The special operator >>> is defined to perform a logical right shift.

Unsigned values are very useful when we want to think of words as just collections of bits with no numeric interpretation. This occurs, for example, when packing a word with flags describing various Boolean conditions. Addresses are naturally unsigned, so systems programmers find unsigned types to be helpful. Unsigned values are also useful when implementing mathematical packages for modular arithmetic and for multiprecision arithmetic, in which numbers are represented by arrays of words.

{% hint style="info" %}
#### Aside --- Security vulnerability in getpeername

In 2002, programmers involved in the FreeBSD open-source operating systems project realized that their implementation of the `getpeername` library function had a security vulnerability. A simplified version of their code went something like picture A.

In this code, we show the prototype for library function `memcpy` on line 7, which is designed to copy a specified number of bytes n from one region of memory to another.

The function `copy_from_kernel`, starting at line 14, is designed to copy some of the data maintained by the operating system kernel to a designated region of memory accessible to the user. Most of the data structures maintained by the kernel should not be readable by a user, since they may contain sensitive information about other users and about other jobs running on the system, but the region shown as kbuf was intended to be one that the user could read. The parameter `maxlen` is intended to be the length of the buffer allocated by the user and indicated by argument `user_dest`. The computation at line 16 then makes sure that no more bytes are copied than are available in either the source or the destination buffer.

Suppose, however, that some malicious programmer writes code that calls `copy_from_kernel` with a negative value of `maxlen`. Then the minimum computation on line 16 will compute this value for len, which will then be passed as the parameter n to memcpy. Note, however, that parameter n is declared as having data type `size_t`. This data type is declared (via typedef) in the library file stdio.h. Typically, it is defined to be unsigned for 32-bit programs and unsigned long for 64-bit programs. Since argument n is unsigned, memcpy will treat it as a very large positive number and attempt to copy that many bytes from the kernel region to the user’s buffer. Copying that many bytes (at least $$2^{31}$$) will not actually work, because the program will encounter invalid addresses in the process, but the program could read regions of the kernel memory for which it is not authorized.

We can see that this problem arises due to the mismatch between data types: in one place the length parameter is signed; in another place it is unsigned. Such mismatches can be a source of bugs and, as this example shows, can even lead to security vulnerabilities. Fortunately, there were no reported cases where a programmer had exploited the vulnerability in FreeBSD. They issued a security advisory “FreeBSD-SA-02:38.signed-error” advising system administrators on how to apply a patch that would remove the vulnerability. The bug can be fixed by declaring parameter maxlen to copy\_from\_kernel to be of type size\_t, to be consistent with parameter n of `memcpy`. We should also declare local variable len and the return value to be of type `size_t`.
{% endhint %}

![pciture A. The code of getpeername ](<../../.gitbook/assets/image (23) (1) (1).png>)
