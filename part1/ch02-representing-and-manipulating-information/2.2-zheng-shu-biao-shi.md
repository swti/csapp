# 2.2 Integer Representations

In this section, we describe two different ways bits can be used to encode integers — one that can only represent nonnegative numbers, and one that can represent negative, zero, and positive numbers. We will see later that they are strongly related both in their mathematical properties and their machine-level implementations. We also investigate the effect of expanding or shrinking an encoded integer to fit a representation with a different length.

Figure 2.8 lists the mathematical terminology we introduce to precisely define and characterize how computers encode and operate on integer data. This terminology will be introduced over the course of the presentation. The figure is included here as a reference.

![Figure 2.8 Terminology for integer data and arithmetic operations. The subscript w denotes the number of bits in the data representation.](<../../.gitbook/assets/image (13) (1).png>)

## 2.2.1 Integral Data Types

C supports a variety of integral data types — ones that represent finite ranges of integers. These are shown in Figures 2.9 and 2.10, along with the ranges of values they can have for “typical” 32- and 64-bit programs. Each type can specify a size with keyword `char`, `short`, `long`, as well as an indication of whether the represented numbers are all nonnegative (declared as unsigned), or possibly negative (the default.) As we saw in Figure 2.3, the number of bytes allocated for the different sizes varies according to whether the program is compiled for 32 or 64 bits. Based on the byte allocations, the different sizes allow different ranges of values to be represented. The only machine-dependent range indicated is for size designator long. Most 64-bit programs use an 8-byte representation, giving a much wider range of values than the 4-byte representation used with 32-bit programs.

![Figure 2.9 Typical ranges for C integral data types for 32-bit programs.](<../../.gitbook/assets/image (7).png>)

![Figure 2.10 Typical ranges for C integral data types for 64-bit programs.](<../../.gitbook/assets/image (17) (1).png>)

One important feature to note in Figures 2.9 and 2.10 is that the ranges are not symmetric—the range of negative numbers extends one further than the range of positive numbers. We will see why this happens when we consider how negative numbers are represented.

The C standards define minimum ranges of values that each data type must be able to represent. As shown in Figure 2.11, their ranges are the same or smaller than the typical implementations shown in Figures 2.9 and 2.10. In particular, with the exception of the fixed-size data types, we see that they require only a symmetric range of positive and negative numbers. We also see that data type `int` could be implemented with 2-byte numbers, although this is mostly a throwback to the days of 16-bit machines. We also see that size `long` can be implemented with 4-byte numbers, and it typically is for 32-bit programs. The fixed-size data types guarantee that the ranges of values will be exactly those given by the typical numbers of Figure 2.9, including the asymmetry between negative and positive.

![Figure 2.11 Guaranteed ranges for C integral data types. The C standards require that the data types have at least these ranges of values.](<../../.gitbook/assets/image (20) (1).png>)

{% hint style="info" %}
#### New to C? --- Signed and unsigned numbers in C, C++, and Java

Both C and C++ support signed (the default) and unsigned numbers. Java supports only signed numbers.
{% endhint %}

## 2.2.2 Unsigned Encodings

Let us consider an integer data type of w bits. We write a bit vector as either <img src="../../.gitbook/assets/image (9) (1).png" alt="" data-size="line">, to denote the entire vector, or as \[$$x_{w-1}$$, $$x_{w-2}$$, ..., $$x_0$$] to denote the individual bits within the vector. Treating x as a number written in binary notation, we obtain the unsigned interpretation of x . In this encoding, each bit $$x_i$$ has value 0 or 1, with the latter case indicating that value $$2^i$$ should be included as part of the numeric value. We can express this interpretation as a function $$B2U_w$$ (for “binary to unsigned,” length w):

![](<../../.gitbook/assets/image (1).png>)

In this equation, the notation <img src="../../.gitbook/assets/image (4).png" alt="" data-size="line"> means that the left-hand side is defined to be equal to the right-hand side. The function $$B2U_w$$ maps strings of zeros and ones of length w to nonnegative integers. As examples, Figure 2.12 shows the mapping, given by B2U, from bit vectors to integers for the following cases:

![](<../../.gitbook/assets/image (15) (1).png>)

In the figure, we represent each bit position i by a rightward-pointing blue bar of length $$2^i$$. The numeric value associated with a bit vector then equals the sum of the lengths of the bars for which the corresponding bit values are 1.

![Figure 2.12 Unsigned number examples for w = 4. When bit i in the binary representation has value 1, it contributes 2i to the value.](<../../.gitbook/assets/image (18) (1).png>)

Let us consider the range of values that can be represented using w bits. The least value is given by bit vector \[00 ... 0] having integer value 0, and the greatest value is given by bit vector \[11 ... 1] having integer value <img src="../../.gitbook/assets/image (11) (1).png" alt="" data-size="original"> = $$2^w$$ − 1. Using the 4-bit case as an example, we have $$UMax_4$$ = $$B2U_4$$(\[1111]) = $$2^4$$ − 1= 15. Thus, the function $$B2U_w$$ can be defined as a mapping $$B2U_w$$:$$\{0, 1\}^w$$ → {0, ..., $$UMax_w$$}.

The unsigned binary representation has the important property that every number between 0 and $$2^w$$ − 1 has a unique encoding as a w-bit value. For example, there is only one representation of decimal value 11 as an unsigned 4-bit number— namely, \[1011]. We highlight this as a mathematical principle, which we first state and then explain.

![](<../../.gitbook/assets/image (10) (1).png>)

The mathematical term **bijection** refers to a function f that goes two ways: it maps a value x to a value y where y = f (x), but it can also operate in reverse, since for every y, there is a unique value x such that f (x) = y. This is given by the inverse function $$f^{−1}$$, where, for our example, x = $$f^{-1}$$(y). The function $$B2U_w$$ maps each bit vector of length w to a unique number between 0 and $$2^w$$ − 1, and it has an inverse, which we call $$U2B_w$$ (for “unsigned to binary”), that maps each number in the range 0 to $$2^w$$ − 1 to a unique pattern of w bits.

## 2.2.3 Two’s-Complement Encodings

For many applications, we wish to represent negative values as well. The most common computer representation of signed numbers is known as two’s-complement form. This is defined by interpreting the most significant bit of the word to have **negative weight**. We express this interpretation as a function $$B2T_w$$ (for “binary to two’s complement” length w):

![](<../../.gitbook/assets/image (12).png>)

The most significant bit $$x_{w−1}$$ is also called the sign bit. Its “weight” is $$−2^{w−1}$$, the negation of its weight in an unsigned representation. When the sign bit is set to 1, the represented value is negative, and when set to 0, the value is nonnegative. As examples, Figure 2.13 shows the mapping, given by B2T, from bit vectors to integers for the following cases:

![](<../../.gitbook/assets/image (20).png>)

In the figure, we indicate that the sign bit has negative weight by showing it as a leftward-pointing gray bar. The numeric value associated with a bit vector is then given by the combination of the possible leftward-pointing gray bar and the rightward-pointing blue bars.

![Figure 2.13 Two’s-complement number examples for w = 4. Bit 3 serves as a sign bit; when set to 1, it contributes − = −8 to the value. This weighting is shown as a leftwardpointing gray bar.](<../../.gitbook/assets/image (14).png>)

We see that the bit patterns are identical for Figures 2.12 and 2.13 (as well as for Equations 2.2 and 2.4), but the values differ when the most significant bit is 1, since in one case it has weight +8, and in the other case it has weight −8.

Let us consider the range of values that can be represented as a w-bit two’scomplement number. The least representable value is given by bit vector \[10 ... 0] (set the bit with negative weight but clear all others), having integer value <img src="../../.gitbook/assets/image (8).png" alt="" data-size="line">. The greatest value is given by bit vector \[01 ... 1] (clear the bit with negative weight but set all others), having integer value ![](<../../.gitbook/assets/image (11).png>) $$2^{w-1}$$-1. Using the 4-bit case as an example, we have $$TMin_4$$ = $$B2T_4$$(\[1000]) = −23 = −8 and $$TMax_4$$ = $$B2T_4$$(\[0111]) = 22 + 21 + 20 = 4 + 2 + 1 = 7.

We can see that $$B2T_w$$ is a mapping of bit patterns of length w to numbers between $$TMin_w$$ and $$TMax_w$$, written as $$B2T_w$$:$$\{0, 1\}^w$$ → {$$TMin_w$$,..., $$TMax_w$$}. As we saw with the unsigned representation, every number within the representable range has a unique encoding as a w-bit two’s-complement number. This leads to a principle for two’s-complement numbers similar to that for unsigned numbers:

![](<../../.gitbook/assets/image (10).png>)

We define function $$T2B_w$$ (for “two’s complement to binary”) to be the inverse of $$B2T_w$$. That is, for a number x, such that $$TMin_w$$ ≤ x ≤ $$TMax_w$$, $$T2B_w$$(x) is the (unique) w-bit pattern that encodes x.

{% tabs %}
{% tab title="Practice Problem 2.17 " %}
Assuming w = 4, we can assign a numeric value to each possible hexadecimal digit, assuming either an unsigned or a two’s-complement interpretation. Fill in the following table according to these interpretations by writing out the nonzero powers of 2 in the summations shown in Equations 2.1 and 2.3:

![](<../../.gitbook/assets/image (18).png>)
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="Solution 2.17" %}
0x1: 0001    2^1=1    2^1=1

0xB: 1011    2^3+2^1+2^0=11    -2^3+2^1+2=-5

0x2: 0010    2^1=2    2^1=2

0x7: 0111    2^2+2^1+2^0=7    2^2+2^1+2^0=7

0xC: 1100    2^3+2^2=12    -2^3+2^2=-4
{% endtab %}
{% endtabs %}

Figure 2.14 shows the bit patterns and numeric values for several important numbers for different word sizes. The first three give the ranges of representable integers in terms of the values of $$UMax_w$$, $$TMin_w$$, and $$TMax_w$$. We will refer to these three special values often in the ensuing discussion. We will drop the subscript w and refer to the values UMax, TMin, andTMax when w can be inferred from context or is not central to the discussion.

A few points are worth highlighting about these numbers. First, as observed in Figures 2.9 and 2.10, the two’s-complement range is asymmetric: |TMin| = |TMax| + 1; that is, there is no positive counterpart to TMin. As we shall see, this leads to some peculiar properties of two’s-complement arithmetic and can be the source of subtle program bugs. This asymmetry arises because half the bit patterns (those with the sign bit set to 1) represent negative numbers, while half (those with the sign bit set to 0) represent nonnegative numbers. Since 0 is nonnegative, this means that it can represent one less positive number than negative. Second, the maximum unsigned value is just over twice the maximum two’s-complement value: UMax = 2TMax + 1. All of the bit patterns that denote negative numbers in two’s-complement notation become positive values in an unsigned representation.

![Figure 2.14 Important numbers. Both numeric values and hexadecimal representations are shown.](<../../.gitbook/assets/image (15).png>)

{% hint style="info" %}
#### Aside --- More on fixed-size integer types

For some programs, it is essential that data types be encoded using representations with specific sizes. For example, when writing programs to enable a machine to communicate over the Internet according to a standard protocol, it is important to have data types compatible with those specified by the protocol. We have seen that some C data types, especially `long`, have different ranges on different machines, and in fact the C standards only specify the minimum ranges for any data type, not the exact ranges. Although we can choose data types that will be compatible with standard representations on most machines, there is no guarantee of portability.

We have already encountered the 32- and 64-bit versions of fixed-size integer types (Figure 2.3); they are part of a larger class of data types. The ISO C99 standard introduces this class of integer types in the file **stdint.h**. This file defines a set of data types with declarations of the form `intN_t` and `uintN_t`, specifying N-bit signed and unsigned integers, for different values of N. The exact values of N are implementation dependent, but most compilers allow values of 8, 16, 32, and 64. Thus, we can unambiguously declare an unsigned 16-bit variable by giving it type `uint16_t`, and a signed variable of 32 bits as `int32_t`.

Along with these data types are a set of macros defining the minimum and maximum values for each value of N. These have names of the form `INTN_MIN`, `INTN_MAX`, and `UINTN_MAX`.

Formatted printing with fixed-width types requires use of macros that expand into format strings in a system-dependent manner. So, for example, the values of variables x and y of type `int32_t` and `uint64_t` can be printed by the following call to printf:

`printf("x = %" PRId32 ", y = %" PRIu64 "\n", x, y);`

When compiled as a 64-bit program, macro PRId32 **** expands to the string "d", while PRIu64 expands to the pair of strings "l" "u". When the C preprocessor encounters a sequence of string constants separated only by spaces (or other whitespace characters), it concatenates them together. Thus, the above call to printf becomes

`printf("x = %d, y = %lu\n", x, y);`

Using the macros ensures that a correct format string will be generated regardless of how the code is compiled.
{% endhint %}

Figure 2.14 also shows the representations of constants −1 and 0. Note that −1 has the same bit representation as UMax — a string of all ones. Numeric value 0 is represented as a string of all zeros in both representations.

The C standards do not require signed integers to be represented in two’scomplement form, but nearly all machines do so. Programmers who are concerned with maximizing portability across all possible machines should not assume any particular range of representable values, beyond the ranges indicated in Figure 2.11, nor should they assume any particular representation of signed numbers. On the other hand, many programs are written assuming a two’s-complement representation of signed numbers, and the “typical” ranges shown in Figures 2.9 and 2.10, and these programs are portable across a broad range of machines and compilers. The file **\<limits.h>** in the C library defines a set of constants delimiting the ranges of the different integer data types for the particular machine on which the compiler is running. For example, it defines constants `INT_MAX`, `INT_MIN`, and `UINT_MAX` describing the ranges of signed and unsigned integers. For a two’s-complement machine in which data type int has w bits, these constants correspond to the values of $$TMax_w$$, $$TMin_w$$, and $$UMax_w$$.

The Java standard is quite specific about integer data type ranges and representations. It requires a two’s-complement representation with the exact ranges shown for the 64-bit case (Figure 2.10). In Java, the single-byte data type is called `byte` instead of `char`. These detailed requirements are intended to enable Java programs to behave identically regardless of the machines or operating systems running them.

To get a better understanding of the two’s-complement representation, consider the following code example:

```c
short x = 12345;
short mx = -x;

show_bytes((byte_pointer) &x, sizeof(short));
show_bytes((byte_pointer) &mx, sizeof(short));
```

When run on a big-endian machine, this code prints 30 39 and cf c7, indicating that `x` has hexadecimal representation 0x3039, while `mx` has hexadecimal representation 0xCFC7. Expanding these into binary, we get bit patterns \[0011000000111001] for `x` and \[1100111111000111] for `mx`. As Figure 2.15 shows, Equation 2.3 yields values 12,345 and −12,345 for these two bit patterns.

![Figure 2.15 Two’s-complement representations of 12,345 and −12,345, and unsigned representation of 53,191. Note that the latter two have identical bit representations.](<../../.gitbook/assets/image (16).png>)

{% hint style="info" %}
#### Aside --- Alternative representations of signed numbers

There are two other standard representations for signed numbers:

**Ones’ complement**. This is the same as two’s complement, except that the most significant bit has weight −($$2^{w−1}$$ − 1) rather than −$$2^{w−1}$$:

<img src="../../.gitbook/assets/image (17).png" alt="" data-size="original">\
**Sign magnitude**. The most significant bit is a sign bit that determines whether the remaining bits should be given negative or positive weight:

![](<../../.gitbook/assets/image (9).png>)\
Both of these representations have the curious property that there are two different encodings of the number 0. For both representations, \[00 ... 0] is interpreted as +0. The value −0 can be represented in sign-magnitude form as \[10 ... 0] and in ones’ complement as \[11 ... 1]. Although machines based on ones’-complement representations were built in the past, almost all modern machines use two’s complement. We will see that sign-magnitude encoding is used with floating-point numbers.

Note the different position of apostrophes: two’s complement versus ones’ complement. The term “two’s complement” arises from the fact that for nonnegative x we compute a w-bit representation of −x as $$2^w$$ − x (a single two.) The term “ones’ complement” comes from the property that we can compute −x in this notation as \[111 ... 1] − x (multiple ones).
{% endhint %}

{% tabs %}
{% tab title="Practice Problem 2.18" %}
In Chapter 3, we will look at listings generated by a disassembler, a program that converts an executable program file back to a more readable ASCII form. These files contain many hexadecimal numbers, typically representing values in two’scomplement form. Being able to recognize these numbers and understand their significance (for example, whether they are negative or positive) is an important skill.

For the lines labeled A–I (on the right) in the following listing, convert the hexadecimal values (in 32-bit two’s-complement form) shown to the right of the instruction names (`sub`, `mov`, and `add`) into their decimal equivalents:

![](<../../.gitbook/assets/image (13).png>)
{% endtab %}
{% endtabs %}

{% tabs %}
{% tab title="Solution 2.18" %}
A. 0x2e0 => 743

B. -0x58 => -88

C. 0x28 => 40

D. -0x30 => -48

E. 0x78 => 120

F. 0x88 => 136

G. 0x1f8 => 504

H. 0xc0 => 192

I. -0x48 => -72
{% endtab %}
{% endtabs %}

## 2.2.4 Conversions between Signed and Unsigned

C allows casting between different numeric data types. For example, suppose variable x is declared as `int` and u as `unsigned`. The expression (unsigned) x converts the value of x to an unsigned value, and (int) u converts the value of u to a signed integer. What should be the effect of casting signed value to unsigned, or vice versa? From a mathematical perspective, one can imagine several different conventions. Clearly, we want to preserve any value that can be represented in both forms. On the other hand, converting a negative value to unsigned might yield zero. Converting an unsigned value that is too large to be represented in two’scomplement form might yield TMax. For most implementations of C, however, the answer to this question is based on a bit-level perspective, rather than on a numeric one.

For example, consider the following code:

```c
short int v = -12345;
unsigned short uv = (unsigned short) v;
printf("v = %d, uv = %u\n", v, uv);
```

When run on a two’s-complement machine, it generates the following output:

`v = -12345, uv = 53191`

What we see here is that the effect of casting is to keep the bit values identical but change how these bits are interpreted. We saw in Figure 2.15 that the 16-bit two’s-complement representation of −12,345 is identical to the 16-bit unsigned representation of 53,191. Casting from `short` to `unsigned short` changed the numeric value, but not the bit representation.

Similarly, consider the following code:

```c
unsigned u = 4294967295u; /* UMax */
int tu = (int) u;
printf("u = %u, tu = %d\n", u, tu);
```

When run on a two’s-complement machine, it generates the following output:

`u = 4294967295, tu = -1`

We can see from Figure 2.14 that, for a 32-bit word size, the bit patterns representing 4,294,967,295 (UMax32) in unsigned form and −1 in two’s-complement form are identical. In casting from unsigned to int, the underlying bit representation stays the same.
