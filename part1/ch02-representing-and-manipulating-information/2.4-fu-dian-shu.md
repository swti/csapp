# 2.4 Floating Point

A floating-point representation encodes rational numbers of the form V = $$x × 2^y$$. It is useful for performing computations involving very large numbers (|V| $$\gg$$ 0), numbers very close to 0 (|V| $$\ll$$ 1), and more generally as an approximation to real arithmetic.

Up until the 1980s, every computer manufacturer devised its own conventions for how floating-point numbers were represented and the details of the operations performed on them. In addition, they often did not worry too much about the accuracy of the operations, viewing speed and ease of implementation as being more critical than numerical precision.

All of this changed around 1985 with the advent of **IEEE Standard 754**, a carefully crafted standard for representing floating-point numbers and the operations performed on them. This effort started in 1976 under Intel’s sponsorship with the design of the 8087, a chip that provided floating-point support for the 8086 processor. Intel hired William Kahan, a professor at the University of California, Berkeley, as a consultant to help design a floating-point standard for its future processors. They allowed Kahan to join forces with a committee generating an industry-wide standard under the auspices of the Institute of Electrical and Electronics Engineers (IEEE). The committee ultimately adopted a standard close to the one Kahan had devised for Intel. Nowadays, virtually all computers support what has become known as IEEE floating point. This has greatly improved the portability of scientific application programs across different machines.

In this section, we will see how numbers are represented in the IEEE floatingpoint format. We will also explore issues of **rounding**, when a number cannot be represented exactly in the format and hence must be adjusted upward or downward. We will then explore the mathematical properties of addition, multiplication, and relational operators. Many programmers consider floating point to be at best uninteresting and at worst arcane and incomprehensible. We will see that since the IEEE format is based on a small and consistent set of principles, it is really quite elegant and understandable.

{% hint style="info" %}
#### Aside --- The IEEE

The Institute of Electrical and Electronics Engineers (IEEE — pronounced “eye-triple-ee”) is a professional society that encompasses all of electronic and computer technology. It publishes journals, sponsors conferences, and sets up committees to define standards on topics ranging from power transmission to software engineering. Another example of an IEEE standard is the 802.11 standard for wireless networking.
{% endhint %}

## 2.4.1 Fractional Binary Numbers

A first step in understanding floating-point numbers is to consider binary numbers having fractional values. Let us first examine the more familiar decimal notation. Decimal notation uses a representation of the form

$$
d_m d_{m−1} ... d_1 d_0 . d_{−1} d_{−2} ... d_{−n}
$$

where each decimal digit $$d_i$$ ranges between 0 and 9. This notation represents a value d defined as

$$
d = \sum ^m_{i=-n} 10^i \times d_i
$$

The weighting of the digits is defined relative to the **decimal point** symbol (‘.’), meaning that digits to the left are weighted by nonnegative powers of 10, giving integral values, while digits to the right are weighted by negative powers of 10, giving fractional values. For example, 12.3410 represents the number $$1 \times 10^1 + 2 \times 10^0 + 3 \times 10^{−1} + 4 \times 10^{−2} = 12 \frac{34}{100}$$.

By analogy, consider a notation of the form

$$
b_m b_{m−1} ... b_1 b_0 . b_{−1} b_{−2} ... b_{−n}
$$

where each binary digit, or bit, $$b_i$$ ranges between 0 and 1, as is illustrated in Figure 2.31. This notation represents a number b defined as

$$
b = \sum^m_{i=-n} 2^i \times b_i \tag{2.19}
$$

![Figure 2.31
Fractional binary representation.
Digits to the left of the binary point have weights of the form 2^i , while those to the right have weights of the form 1/2^i .](<../../.gitbook/assets/image (32).png>)

The symbol ‘.’ now becomes a binary point, with bits on the left being weighted by nonnegative powers of 2, and those on the right being weighted by negative powers of 2. For example, $$101.11_2$$ represents the number $$1 × 2^2 + 0 × 2^1 + 1 × 2^0 + 1 × 2^{−1} + 1 × 2^{−2} = 4 + 0 + 1 + \frac{1}{2} + \frac{1}{4} = 5\frac{3}{4}$$.

One can readily see from Equation 2.19 that shifting the binary point one position to the left has the effect of dividing the number by 2. For example, while 101.112 represents the number $$5\frac{3}{4}$$, $$10.111_2$$ represents the number 2 + 0 + 1/2 + 1/4 + 1/8 = 2$$\frac{7}{8}$$. Similarly, shifting the binary point one position to the right has the effect of multiplying the number by 2. For example, $$1011.1_2$$ represents the number 8 + 0 + 2 + 1 + 1/2 = 11$$\frac{1}{2}$$.

Note that numbers of the form $$0.11 ... 1_2$$ represent numbers just below 1. For example, $$0.111111_2$$ represents $$\frac{63}{64}$$. We will use the shorthand notation $$1.0 − \epsilon$$ to represent such values.

Assuming we consider only finite-length encodings, decimal notation cannot represent numbers such as 1/3 and 5/7 exactly. Similarly, fractional binary notation can only represent numbers that can be written $$x \times 2^y$$. Other values can only be approximated. For example, the number 1/5 can be represented exactly as the fractional decimal number 0.20. As a fractional binary number, however, we cannot represent it exactly and instead must approximate it with increasing accuracy by lengthening the binary representation:

![](<../../.gitbook/assets/image (9).png>)

{% tabs %}
{% tab title="Practice Problem 2.45" %}
Fill in the missing information in the following table:

| Fractional value | Binary representation | Decimal representation |
| ---------------- | --------------------- | ---------------------- |
| $$\frac{1}{8}$$  | 0.001                 | 0.125                  |
| $$\frac{3}{4}$$  |                       |                        |
| $$\frac{5}{16}$$ |                       |                        |
|                  | 10.1011               |                        |
|                  | 1.001                 |                        |
|                  |                       | 5.875                  |
|                  |                       | 3.1875                 |
{% endtab %}

{% tab title="Practice Problem 2.46" %}
The imprecision of floating-point arithmetic can have disastrous effects. On February 25, 1991, during the first Gulf War, an American Patriot Missile battery in Dharan, Saudi Arabia, failed to intercept an incoming Iraqi Scud missile. The Scud struck an American Army barracks and killed 28 soldiers. The US General Accounting Office (GAO) conducted a detailed analysis of the failure \[76] and determined that the underlying cause was an imprecision in a numeric calculation. In this exercise, you will reproduce part of the GAO’s analysis.

The Patriot system contains an internal clock, implemented as a counter that is incremented every 0.1 seconds. To determine the time in seconds, the program would multiply the value of this counter by a 24-bit quantity that was a fractional binary approximation to $$\frac{1}{10}$$. In particular, the binary representation of $$\frac{1}{10}$$ is the nonterminating sequence $$0.000110011[0011]..._2$$, where the portion in brackets is repeated indefinitely. The program approximated 0.1, as a value x, by considering just the first 23 bits of the sequence to the right of the binary point: x = 0.00011001100110011001100. (See Problem 2.51 for a discussion of how they could have approximated 0.1 more precisely.)

A. What is the binary representation of 0.1 − x?

B. What is the approximate decimal value of 0.1 − x?

C. The clock starts at 0 when the system is first powered up and keeps counting up from there. In this case, the system had been running for around 100 hours. What was the difference between the actual time and the time computed by the software?

D. The system predicts where an incoming missile will appear based on its velocity and the time of the last radar detection. Given that a Scud travels at around 2,000 meters per second, how far off was its prediction?

Normally, a slight error in the absolute time reported by a clock reading would not affect a tracking computation. Instead, it should depend on the relative time between two successive readings. The problem was that the Patriot software had been upgraded to use a more accurate function for reading time, but not all of the function calls had been replaced by the new code. As a result, the tracking software used the accurate time for one reading and the inaccurate time for the other \[103].
{% endtab %}
{% endtabs %}



{% tabs %}
{% tab title="Solution 2.45" %}


| Fractional value    | Binary representation | Decimal representation |
| ------------------- | --------------------- | ---------------------- |
| $$\frac{1}{8}$$     | 0.001                 | 0.125                  |
| $$\frac{3}{4}$$     | 0.11                  | 0.75                   |
| $$\frac{5}{16}$$    | 0.0101                | 0.3125                 |
| 10$$\frac{11}{16}$$ | 10.1011               | 10.6875                |
| 1$$\frac{1}{8}$$    | 1.001                 | 1.125                  |
| 5$$\frac{7}{8}$$    | 101.111               | 5.875                  |
| 3$$\frac{3}{16}$$   | 11.0011               | 3.1875                 |
{% endtab %}

{% tab title="Solution 2.46" %}
A. $$0.000110011[0011]..._2$$ - $$0.00011001100110011001100_2$$ = $$0.0000000000000000000000011[0011]..._2$$

\
B. 0.1 - x = 0.1 - 0.09999990463256836 = 0.00000009536743164

\
C. 0.00000009536743164 \* 10 \* 60 \* 100 = 0.0057220458984 (s)

\
D. 0.0057220458984 \* 2000 = 11.4440917968 (m)
{% endtab %}
{% endtabs %}

## 2.4.2 IEEE Floating-Point Representation

Positional notation such as considered in the previous section would not be efficient for representing very large numbers. For example, the representation of $$5 \times 2^{100}$$ would consist of the bit pattern 101 followed by 100 zeros. Instead, we would like to represent numbers in a form $$x \times 2^y$$ by giving the values of x and y.

The IEEE floating-point standard represents a number in a form $$V = (−1)^s \times M \times 2^E$$:

* The **sign** s determines whether the number is negative (s = 1) or positive (s = 0), where the interpretation of the sign bit for numeric value 0 is handled as a special case.
* The **significand** M is a fractional binary number that ranges either between 1 and 2 − $$\epsilon$$ or between 0 and 1 − $$\epsilon$$.
* The **exponent** E weights the value by a (possibly negative) power of 2.

The bit representation of a floating-point number is divided into three fields to encode these values:

* The **single sign bit** s directly encodes the sign s.
* The **k-bit exponent field** $$exp = e_{k−1} ... e_1e_0$$ encodes the exponent E.
* The **n-bit fraction field** $$frac = f_{n−1} ... f_1f_0$$ encodes the significand M, but the value encoded also depends on whether or not the exponent field equals 0.

Figure 2.32 shows the packing of these three fields into words for the two most common formats. In the single-precision floating-point format (a `float` in C), fields s, exp, and frac are 1, k = 8, and n = 23 bits each, yielding a 32- bit representation. In the double-precision floating-point format (a double in C), fields s, exp, and frac are 1, k = 11, and n = 52 bits each, yielding a 64-bit representa-tion.

![Figure 2.32
Standard floating-point formats.
Floating-point numbers are represented by three fields.
For the two most common formats, these are packed in 32-bit (singleprecision) or 64-bit (double-precision) words.](<../../.gitbook/assets/image (14).png>)

The value encoded by a given bit representation can be divided into three different cases (the latter having two variants), depending on the value of exp. These are illustrated in Figure 2.33 for the single-precision format.

![Figure 2.33
Categories of single-precision floating-point values.
The value of the exponent determines whether the number is (1) normalized, (2) denormalized, or (3) a special value.](<../../.gitbook/assets/image (18).png>)

#### <mark style="color:blue;">Case 1: Normalized Values</mark>

This is the most common case. It occurs when the bit pattern of exp is neither all zeros (numeric value 0) nor all ones (numeric value 255 for single precision, 2047 for double). In this case, the exponent field is interpreted as representing a signed integer in biased form. That is, the exponent value is **E = e − Bias**, where e is the unsigned number having bit representation $$e_{k−1} ... e_1e_0$$ and Bias is a bias value equal to $$2^{k−1} − 1$$ (127 for single precision and 1023 for double). This yields exponent ranges from −126 to +127 for single precision and −1022 to +1023 for double precision.

The fraction field frac is interpreted as representing the fractional value f , where 0 ≤ f < 1, having binary representation $$0.f_{n−1} ... f_1f_0$$, that is, with the binary point to the left of the most significant bit. The significand is defined to be **M = 1 + f**. This is sometimes called an implied leading 1 representation, because we can view M to be the number with binary representation $$1.f_{n−1}f_{n−2} ... f_{0}$$. This representation is a trick for getting an additional bit of precision for free, since we can always adjust the exponent E so that significand M is in the range 1 ≤ M < 2 (assuming there is no overflow). We therefore do not need to explicitly represent the leading bit, since it always equals 1.

#### <mark style="color:blue;">Case 2: Denormalized Values</mark>

When the exponent field is all zeros, the represented number is in denormalized form. In this case, the exponent value is **E = 1 − Bias**, and the significand value is **M = f** , that is, the value of the fraction field without an implied leading 1.

Denormalized numbers serve two purposes.\ <mark style="color:blue;"></mark>First, they provide a way to represent numeric value 0, since with a normalized number we must always have M ≥ 1, and hence we cannot represent 0. In fact, the floating-point representation of +0.0 has a bit pattern of all zeros: the sign bit is 0, the exponent field is all zeros (indicating a denormalized value), and the fraction field is all zeros, giving M = f = 0. Curiously, when the sign bit is 1, but the other fields are all zeros, we get the value −0.0. With IEEE floating-point format, the values −0.0 and +0.0 are considered different in some ways and the same in others.\
A second function of denormalized numbers is to represent numbers that are very close to 0.0. They provide a property known as **gradual underflow** in which possible numeric values are spaced evenly near 0.0.

#### <mark style="color:blue;">Case 3: Special Values</mark>

A final category of values occurs when the exponent field is all ones.\
When the fraction field is all zeros, the resulting values represent **infinity**, either $$+\infty$$ when s = 0 or $$-\infty$$ when s = 1. Infinity can represent results that overflow, as when we multiply two very large numbers, or when we divide by zero. When the fraction field is nonzero, the resulting value is called a **NaN**, short for “not a number.” Such values are returned as the result of an operation where the result cannot be given as a real number or as infinity, as when computing $$\sqrt[]{-1}$$ or $$\infty - \infty$$. They can also be useful in some applications for representing uninitialized data.

{% hint style="info" %}
#### Aside --- Why set the bias this way for denormalized values?

Having the exponent value be 1 − Bias rather than simply −Bias might seem counterintuitive. We will see shortly that it provides for smooth transition from denormalized to normalized values.
{% endhint %}

## 2.4.3 Example Numbers

## 2.4.4 Rounding

## 2.4.5 Floating-Point Operations

## 2.4.6 Floating Point in C
